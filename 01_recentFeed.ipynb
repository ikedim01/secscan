{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp recentFeed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# recentFeed\n",
    "\n",
    "> Parse the SEC's recent filings feed, and XBRL filings feed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from nbdev import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import re\n",
    "import xml.etree.cElementTree as cElTree\n",
    "\n",
    "from secscan import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and parse the SEC's recent filings feed, and XBRL filings feed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def secMostRecentListUrl(count=100) :\n",
    "    \"Returns the URL for the SEC's atom-format feed of most recent filings.\"\n",
    "    return ('/cgi-bin/browse-edgar?'\n",
    "            +('' if count is None else f'count={count}&')\n",
    "            +'action=getcurrent&output=atom')\n",
    "\n",
    "def printXmlParseWarning(msg,el) :\n",
    "    print('***',msg,'***')\n",
    "    print(cElTree.tostring(el))\n",
    "    print('************************')\n",
    "\n",
    "titlePat = re.compile(\n",
    "        r\"\\s*(.+?)\\s+-\" # formType, ignoring surrounding whitespace\n",
    "        + r\"\\s+(.+?)\\s*\" # cikName, ignoring surrounding whitespace\n",
    "        + r\"\\((\\d{10})\\)\") # cik\n",
    "filedPat = re.compile(\n",
    "        r\"filed\\D+?\\s(\\d\\d\\d\\d[-/]?\\d\\d[-/]?\\d\\d)\\s.*\"\n",
    "        + r\"accno\\D+?\\s(\"+utils.accessNoPatStr+r\")\\s\",\n",
    "        re.IGNORECASE)\n",
    "def getRecentChunk(count=100) :\n",
    "    \"\"\"\n",
    "    Parses the SEC's atom-format feed of most recent filings and returns a list of tuples:\n",
    "        [(fileDate, cikName, accNo, formType, cik),\n",
    "         ... ]\n",
    "    with the most recent filings first\n",
    "    \"\"\"\n",
    "    mrListXml = utils.downloadSecUrl(secMostRecentListUrl(count=count), toFormat='xml')\n",
    "    res = []\n",
    "    for listEntry in mrListXml :\n",
    "        if not listEntry.tag.lower().endswith(\"entry\") :\n",
    "            continue\n",
    "        cik = formType = accNo = fDate = cikName = None\n",
    "        for entryItem in listEntry :\n",
    "            itemTag = entryItem.tag.lower()\n",
    "            if itemTag.endswith('title') :\n",
    "                # print('\"'+entryItem.text.strip()+'\"')\n",
    "                m = titlePat.match(entryItem.text)\n",
    "                if m is None :\n",
    "                    printXmlParseWarning('unable to parse title element',listEntry)\n",
    "                    continue\n",
    "                formType,cikName,cik = m.groups()\n",
    "                cik = cik.lstrip('0')\n",
    "                # print(repr(formType),repr(cikName),repr(cik))\n",
    "            elif itemTag.endswith('summary') :\n",
    "                # print('\"'+entryItem.text.strip()+'\"')\n",
    "                m = filedPat.search(entryItem.text)\n",
    "                if m is None :\n",
    "                    printXmlParseWarning('unable to parse summary element',listEntry)\n",
    "                    continue\n",
    "                fDate,accNo = m.groups()\n",
    "                # print(repr(fDate),repr(accNo))\n",
    "        fTup = (fDate, cikName, accNo, formType, cik)\n",
    "        if all(fTup) :\n",
    "            res.append(fTup)\n",
    "    return res\n",
    "\n",
    "secXbrlFeedUrl = '/Archives/edgar/xbrlrss.all.xml'\n",
    "dateStrMMDDPat = re.compile(r\"(\\d\\d)[/\\-](\\d\\d)[/\\-](\\d\\d\\d\\d)$\")\n",
    "def getXbrlFeed() :\n",
    "    s = utils.downloadSecUrl(secXbrlFeedUrl, toFormat='soup')\n",
    "    l = s.find_all('item')\n",
    "    # print(len(l),'XBRL items')\n",
    "    res = []\n",
    "    for item in l :\n",
    "        try :\n",
    "            itemL = [item.find('edgar:'+tag).string.strip()\n",
    "                     for tag in ['filingdate','companyname','accessionnumber','formtype','ciknumber']]\n",
    "            m = dateStrMMDDPat.match(itemL[0])\n",
    "            if m is None :\n",
    "                raise Exception(\"MM/DD/YYYY format expected for filingdate\")\n",
    "            itemL[0] = m.group(3)+'-'+m.group(1)+'-'+m.group(2)\n",
    "            itemL[4] = itemL[4].lstrip('0')\n",
    "            res.append(tuple(itemL))\n",
    "        except Exception as e:\n",
    "            print('**** ERROR',e)\n",
    "            print('**** PARSING',item)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test downloading and parsing the SEC's recent filings feed and XBRL filings feed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recent filings feed:\n",
      "0 ('2022-01-14', 'Brannan Michael A.', '0001654954-22-000545', '4', '1807248')\n",
      "1 ('2022-01-14', 'AEHR TEST SYSTEMS', '0001654954-22-000545', '4', '1040470')\n",
      "2 ('2022-01-14', 'Burdick Kenneth A', '0001071739-22-000032', '3', '1498992')\n",
      "3 ('2022-01-14', 'CENTENE CORP', '0001071739-22-000032', '3', '1071739')\n",
      "4 ('2022-01-14', 'SPINK KENNETH B.', '0001654954-22-000544', '4', '1652627')\n",
      "\n",
      "XBRL filings feed:\n",
      "0 ('2022-01-14', 'Recro Pharma, Inc.', '0000950170-22-000333', '8-K/A', '1588972')\n",
      "1 ('2022-01-14', 'CXJ GROUP CO., Ltd', '0001493152-22-001328', '10-Q', '1823635')\n",
      "2 ('2022-01-14', 'CAMBER ENERGY, INC.', '0001477932-22-000282', '8-K', '1309082')\n",
      "3 ('2022-01-14', 'Coursera, Inc.', '0001193125-22-010064', '8-K', '1651562')\n",
      "4 ('2022-01-14', 'Breeze Holdings Acquisition Corp.', '0001564590-22-001386', '10-Q', '1817640')\n"
     ]
    }
   ],
   "source": [
    "l = getRecentChunk()\n",
    "print('recent filings feed:')\n",
    "utils.printSamp(l,5)\n",
    "assert len(l)==100, 'parsing SEC recent filings feed'\n",
    "print()\n",
    "\n",
    "lxbrl = getXbrlFeed()\n",
    "print('XBRL filings feed:')\n",
    "utils.printSamp(lxbrl,5)\n",
    "assert len(lxbrl)==200, 'parsing SEC XBRL filings feed'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accumulating the recent filings feed to an S3 bucket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def curEasternTimeStampAndDate() :\n",
    "    nowET = utils.curEasternUSTime()\n",
    "    ts = nowET.isoformat().replace('T',' ')\n",
    "    return nowET, ts[:19], ts[:10]\n",
    "\n",
    "def initRecentFeedS3(bucket, prevDay=None) :\n",
    "    _, curTS, today = curEasternTimeStampAndDate()\n",
    "    utils.pickSaveToS3(bucket, 'today-feed.pkl',\n",
    "                       {'updated':curTS, 'filings':set(), 'curDay':today, 'prevDay':None},\n",
    "                       use_gzip=True, make_public=True, protocol=2)\n",
    "\n",
    "def updateRecentFeedS3(bucket, skipOffHours=True) :\n",
    "    nowET, curTS, today = curEasternTimeStampAndDate()\n",
    "    print('updating at', curTS, end='; ')\n",
    "    if skipOffHours and (utils.isWeekend(nowET)\n",
    "                         #or nowET.hour<6 or nowET.hour>22\n",
    "                         #or (nowET.hour==22 and nowET.minute>10)\n",
    "                        ) :\n",
    "        print('SEC off hours, skipping update')\n",
    "        return\n",
    "    l = getRecentChunk()\n",
    "    curFeed = utils.pickLoadFromS3(bucket, 'today-feed.pkl', use_gzip=True)\n",
    "    print('last update', curFeed['updated'])\n",
    "    if today != curFeed['curDay'] :\n",
    "        print('starting new day; last day found was',curFeed['curDay'])\n",
    "        utils.pickSaveToS3(bucket, curFeed['curDay']+'-feed.pkl', curFeed,\n",
    "                           use_gzip=True, make_public=True, protocol=2)\n",
    "        prevFilings, prevDay = curFeed['filings'], curFeed['curDay']\n",
    "        curFeed = {'filings':set(), 'curDay':today, 'prevDay':prevDay}\n",
    "    elif curFeed['prevDay'] is not None :\n",
    "        print('continuing current day; most recent previous day was',curFeed['prevDay'])\n",
    "        prevFeed = utils.pickLoadFromS3(bucket, curFeed['prevDay']+'-feed.pkl', use_gzip=True)\n",
    "        prevFilings, prevDay = prevFeed['filings'], prevFeed['curDay']\n",
    "    else :\n",
    "        print('continuing current day; no previous day found')\n",
    "        prevFilings, prevDay = set(), None\n",
    "    prevDayCount = newFTodayCount = newFOtherDayCount = 0\n",
    "    for tup in l :\n",
    "        if tup in curFeed['filings'] :\n",
    "            continue\n",
    "        if tup in prevFilings :\n",
    "            prevDayCount += 1\n",
    "            continue\n",
    "        curFeed['filings'].add(tup)\n",
    "        fDate = tup[0]\n",
    "        if fDate == today :\n",
    "            newFTodayCount += 1\n",
    "        else :\n",
    "            newFOtherDayCount += 1\n",
    "            if fDate < today :\n",
    "                print('*** old filing date',tup)\n",
    "            else :\n",
    "                print('*** unexpected future filing date',tup)\n",
    "    print(len(l),'filings,',\n",
    "          prevDayCount,'from prev day,',newFTodayCount,'new fToday,',newFOtherDayCount,'new fOther,',\n",
    "          'total now',len(curFeed['filings']))\n",
    "    curFeed['updated'] = curTS\n",
    "    utils.pickSaveToS3(bucket, 'today-feed.pkl', curFeed,\n",
    "                       use_gzip=True, make_public=True, protocol=2)\n",
    "    print('--- update complete at',curEasternTimeStampAndDate()[1])\n",
    "\n",
    "def getRecentFromS3(bucket, key='today') :\n",
    "    return utils.pickLoadFromS3(bucket, key+'-feed.pkl', use_gzip=True)\n",
    "\n",
    "def getRecentFromS3Public(bucket, key='today') :\n",
    "    return utils.pickLoadFromS3Public(bucket, key+'-feed.pkl', use_gzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# initRecentFeedS3('bucket_name')\n",
    "# updateRecentFeedS3('bucket_name')\n",
    "\n",
    "# r = getRecentFromS3Public('bucket_name')\n",
    "# print(len(r['filings']))\n",
    "# utils.printSamp(sorted(r['filings']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# uncomment and run to regenerate all library Python files\n",
    "# from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
