{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp recentFeed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# recentFeed\n",
    "\n",
    "> Parse the SEC's recent filings feed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from nbdev import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import re\n",
    "import xml.etree.cElementTree as cElTree\n",
    "\n",
    "from secscan import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def secMostRecentListUrl(count=100) :\n",
    "    \"Returns the URL for the SEC's atom-format feed of most recent filings.\"\n",
    "    return ('/cgi-bin/browse-edgar?'\n",
    "            +('' if count is None else f'count={count}&')\n",
    "            +'action=getcurrent&output=atom')\n",
    "\n",
    "def printXmlParseWarning(msg,el) :\n",
    "    print('***',msg,'***')\n",
    "    print(cElTree.tostring(el))\n",
    "    print('************************')\n",
    "\n",
    "titlePat = re.compile(\n",
    "        r\"\\s*(.+?)\\s+-\" # formType, ignoring surrounding whitespace\n",
    "        + r\"\\s+(.+?)\\s*\" # cikName, ignoring surrounding whitespace\n",
    "        + r\"\\((\\d{10})\\)\") # cik\n",
    "filedPat = re.compile(\n",
    "        r\"filed\\D+?\\s(\\d\\d\\d\\d[-/]?\\d\\d[-/]?\\d\\d)\\s.*\"\n",
    "        + r\"accno\\D+?\\s(\"+utils.accessNoPatStr+r\")\\s\",\n",
    "        re.IGNORECASE)\n",
    "def getRecentChunk(count=100) :\n",
    "    \"\"\"\n",
    "    Parses the SEC's atom-format feed of most recent filings and returns a list of tuples:\n",
    "        [(fileDate, cikName, accNo, formType, cik),\n",
    "         ... ]\n",
    "    with the most recent filings first\n",
    "    \"\"\"\n",
    "    mrListXml = cElTree.fromstring(utils.downloadSecUrl(secMostRecentListUrl(count=count)))\n",
    "    res = []\n",
    "    for listEntry in mrListXml :\n",
    "        if not listEntry.tag.lower().endswith(\"entry\") :\n",
    "            continue\n",
    "        cik = formType = accNo = fDate = cikName = None\n",
    "        for entryItem in listEntry :\n",
    "            itemTag = entryItem.tag.lower()\n",
    "            if itemTag.endswith('title') :\n",
    "                # print('\"'+entryItem.text.strip()+'\"')\n",
    "                m = titlePat.match(entryItem.text)\n",
    "                if m is None :\n",
    "                    printXmlParseWarning('unable to parse title element',listEntry)\n",
    "                    continue\n",
    "                formType,cikName,cik = m.groups()\n",
    "                cik = cik.lstrip('0')\n",
    "                # print(repr(formType),repr(cikName),repr(cik))\n",
    "            elif itemTag.endswith('summary') :\n",
    "                # print('\"'+entryItem.text.strip()+'\"')\n",
    "                m = filedPat.search(entryItem.text)\n",
    "                if m is None :\n",
    "                    printXmlParseWarning('unable to parse summary element',listEntry)\n",
    "                    continue\n",
    "                fDate,accNo = m.groups()\n",
    "                # print(repr(fDate),repr(accNo))\n",
    "        fTup = (fDate, cikName, accNo, formType, cik)\n",
    "        if all(fTup) :\n",
    "            res.append(fTup)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test downloading and parsing the recent filings feed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ('2021-06-08', 'Ajila Rohan', '0001104659-21-078439', '3', '1864266')\n",
      "1 ('2021-06-08', 'Global Consumer Acquisition Corp', '0001104659-21-078439', '3', '1846288')\n",
      "2 ('2021-06-08', 'Pai Gautham', '0001104659-21-078438', '3', '1863979')\n",
      "3 ('2021-06-08', 'Global Consumer Acquisition Corp', '0001104659-21-078438', '3', '1846288')\n",
      "4 ('2021-06-08', 'Clausen Tom', '0001104659-21-078437', '3', '1864275')\n"
     ]
    }
   ],
   "source": [
    "l = getRecentChunk()\n",
    "utils.printSamp(l,5)\n",
    "assert len(l)==100, 'parsing recent SEC filings feed'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accumulating the recent filings feed to an S3 bucket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def curEasternTimeStampAndDate() :\n",
    "    nowET = utils.curEasternUSTime()\n",
    "    ts = nowET.isoformat().replace('T',' ')\n",
    "    return nowET, ts[:19], ts[:10]\n",
    "\n",
    "def initRecentFeedS3(bucket, prevDay=None) :\n",
    "    _, curTS, today = curEasternTimeStampAndDate()\n",
    "    utils.pickSaveToS3(bucket, 'today-feed.pkl',\n",
    "                       {'updated':curTS, 'filings':set(), 'curDay':today, 'prevDay':None},\n",
    "                       use_gzip=True, make_public=True, protocol=2)\n",
    "\n",
    "def updateRecentFeedS3(bucket, skipOffHours=True) :\n",
    "    nowET, curTS, today = curEasternTimeStampAndDate()\n",
    "    print('updating at', curTS, end='; ')\n",
    "    if skipOffHours and (utils.isWeekend(nowET)\n",
    "                         or nowET.hour<6 or nowET.hour>22\n",
    "                         or (nowET.hour==22 and nowET.minute>10)) :\n",
    "        print('SEC off hours, skipping update')\n",
    "        return\n",
    "    l = getRecentChunk()\n",
    "    curFeed = utils.pickLoadFromS3(bucket, 'today-feed.pkl', use_gzip=True)\n",
    "    print('last update', curFeed['updated'])\n",
    "    if today != curFeed['curDay'] :\n",
    "        print('starting new day; last day found was',curFeed['curDay'])\n",
    "        utils.pickSaveToS3(bucket, curFeed['curDay']+'-feed.pkl', curFeed,\n",
    "                           use_gzip=True, make_public=True, protocol=2)\n",
    "        prevFilings, prevDay = curFeed['filings'], curFeed['curDay']\n",
    "        curFeed = {'filings':set(), 'curDay':today, 'prevDay':prevDay}\n",
    "    elif curFeed['prevDay'] is not None :\n",
    "        print('continuing current day; most recent previous day was',curFeed['prevDay'])\n",
    "        prevFeed = utils.pickLoadFromS3(bucket, curFeed['prevDay']+'-feed.pkl', use_gzip=True)\n",
    "        prevFilings, prevDay = prevFeed['filings'], prevFeed['curDay']\n",
    "    else :\n",
    "        print('continuing current day; no previous day found')\n",
    "        prevFilings, prevDay = set(), None\n",
    "    newCount = 0\n",
    "    for tup in l :\n",
    "        fDate = tup[0]\n",
    "        fTup = tup[1:]\n",
    "        if fDate == today :\n",
    "            if fTup not in curFeed['filings'] :\n",
    "                newCount += 1\n",
    "                curFeed['filings'].add(fTup)\n",
    "        elif fDate == prevDay :\n",
    "            if fTup not in prevFilings :\n",
    "                print('*** new filing from previous day',tup)\n",
    "        else :\n",
    "            print('*** unexpected filing date',tup)\n",
    "    print(len(l), 'feed filings,', newCount, 'new, total now',len(curFeed['filings']))\n",
    "    curFeed['updated'] = curTS\n",
    "    utils.pickSaveToS3(bucket, 'today-feed.pkl', curFeed,\n",
    "                       use_gzip=True, make_public=True, protocol=2)\n",
    "    print('--- update complete at',curEasternTimeStampAndDate()[1])\n",
    "\n",
    "def getRecentFromS3(bucket, key='today') :\n",
    "    return utils.pickLoadFromS3(bucket, key+'-feed.pkl', use_gzip=True)\n",
    "\n",
    "def getRecentFromS3Public(bucket, key='today') :\n",
    "    return utils.pickLoadFromS3Public(bucket, key+'-feed.pkl', use_gzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initRecentFeedS3('bucket_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = getRecentFromS3Public('bucket_name')\n",
    "# print(len(r['filings']))\n",
    "# utils.printSamp(sorted(r['filings']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# uncomment and run to regenerate all library Python files\n",
    "# from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
