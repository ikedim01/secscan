# AUTOGENERATED! DO NOT EDIT! File to edit: 09_scrape6K.ipynb (unless otherwise specified).

__all__ = ['default6KDir', 'parse6K', 'scraper6K', 'extract6KPats']

# Cell

import collections
import itertools
import os
import re

from secscan import utils, dailyList, basicInfo, infoScraper

default6KDir = os.path.join(utils.stockDataRoot,'scraped6K')

# Cell

extract6KPats = [
    re.compile(r'12g.*?no(?:.{1,20}is marked.{1,100}82.)?(.*)(?:signature|pursuant)',re.IGNORECASE),
    re.compile(r'101\s*\(b\)\s*\(7\)(?:.{1,20}note\s*:.*?on edgar.)?(.*)(?:signature|pursuant)',re.IGNORECASE),
    re.compile(r'20-Fb\)\s*\(1\)(?:.{1,20}note\s*:.*?on edgar.)?(.*)(?:signature|pursuant)',re.IGNORECASE),
    re.compile(r'20-F.{1,40}40-F(.*)(?:signature|pursuant)',re.IGNORECASE),
    re.compile(r'announce[s|d]?(.*)',re.IGNORECASE),
    re.compile(r'explanatory\s+note(.*)',re.IGNORECASE),
    re.compile(r'contents(.*)',re.IGNORECASE),
    re.compile(r'exhibits?(?:\s+index)?(.*)',re.IGNORECASE),
]

def parse6K(accNo, formType=None, textLimit=basicInfo.defaultTextLimit) :
    info = basicInfo.getSecFormInfo(accNo, formType=formType, get99=True, textLimit=textLimit)
    mainText = utils.downloadSecUrl(info['links'][0][3], toFormat='souptext')
    print(mainText)
    for extract6KPat in extract6KPats :
        print('PAT',extract6KPat)
        m = extract6KPat.search(mainText)
        if m :
            m = m.group(1).strip()
            if len(m)>20 :
                break
    if m and len(m)>20 :
        info['mainText'] = m[:textLimit]
    else :
        print('*** no main text')
    return info

class scraper6K(infoScraper.scraperBase) :
    def __init__(self, infoDir=default6KDir, startD=None, endD=None, fSuff='m.pkl', **pickle_kwargs) :
        super().__init__(infoDir, '6-K', startD=startD, endD=endD, fSuff=fSuff, **pickle_kwargs)
    def scrapeInfo(self, accNo, formType=None) :
        return parse6K(accNo, formType), None