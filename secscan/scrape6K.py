# AUTOGENERATED! DO NOT EDIT! File to edit: 09_scrape6K.ipynb (unless otherwise specified).

__all__ = ['default6KDir', 'parse6K', 'scraper6K', 'extract6KPats']

# Cell

import collections
import itertools
import os
import re

from secscan import utils, dailyList, basicInfo, infoScraper

default6KDir = os.path.join(utils.stockDataRoot,'scraped6K')

# Cell

extract6KPats = [
    re.compile(r'12g.*?no(?:.{1,20}is marked.{1,100}82.)?(.*)signature',re.IGNORECASE),
    re.compile(r'101\s*\(b\)\s*\(7\)(?:.{1,20}note\s*:.*?on edgar.)?(.*)signature',re.IGNORECASE),
    re.compile(r'exhibit\s+index(.*)signature',re.IGNORECASE),
    re.compile(r'signature.*exhibit(?:\s+index)?(.*)',re.IGNORECASE),
]

def parse6K(accNo, formType=None, textLimit=500) :
    print(f'[{accNo}]',end=' ')
    info = basicInfo.getSecFormInfo(accNo, formType)
    mainText = utils.downloadSecUrl(info['links'][0][3], toFormat='souptext')
    for extract6KPat in extract6KPats :
        m = extract6KPat.search(mainText)
        if m :
            m = m.group(1).strip()
            if len(m)>20 :
                break
    if m and len(m)>20 :
        info['mainText'] = m[:textLimit]
    else :
        print('*** no main text')
    return info

class scraper6K(infoScraper.scraperBase) :
    def __init__(self, infoDir=default6KDir, startD=None, endD=None, fSuff='m.pkl', **pickle_kwargs) :
        super().__init__(infoDir, '6-K', startD=startD, endD=endD, fSuff=fSuff, **pickle_kwargs)
    def scrapeInfo(self, accNo, formType=None) :
        return parse6K(accNo, formType), None