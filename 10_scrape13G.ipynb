{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp scrape13G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scrape13G\n",
    "\n",
    "> Scrape holdings information from 13G SEC filings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from nbdev import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import collections\n",
    "import datetime\n",
    "import itertools\n",
    "import os\n",
    "import re\n",
    "\n",
    "from secscan import utils, dailyList, basicInfo, infoScraper\n",
    "\n",
    "default13GDir = os.path.join(utils.stockDataRoot,'scraped13G')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13G scraper class - scrape holdings information from the SEC filing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "nSharesPatStr = r'(\\d+(?:[,.]\\d\\d\\d)*)'\n",
    "nPctPatStr = r'(\\d+(?:\\.\\d*)?|\\.\\d+)'\n",
    "form13NshAndPctPats = [\n",
    "    re.compile(r'aggregate\\s+amount.{1,100}?' + nSharesPatStr\n",
    "                + r'.{1,200}?' + r'percent\\s+of\\s+class.{1,100}?' + nPctPatStr + r'\\s*%',\n",
    "                re.IGNORECASE|re.DOTALL),\n",
    "    re.compile(r'item\\s+9\\s*:.*?' + nSharesPatStr\n",
    "                + r'.*?' + r'item\\s+11\\s*:.*?' + nPctPatStr + r'\\s*%',\n",
    "                re.IGNORECASE|re.DOTALL),\n",
    "    re.compile(r'aggregate\\s+amount.{1,100}?' + nSharesPatStr\n",
    "                + r'.{1,200}?' + r'percent\\s+of class.{1,100}?(?!\\D9\\D)\\D' + nPctPatStr,\n",
    "                re.IGNORECASE|re.DOTALL),\n",
    "]\n",
    "def getSec13NshAndPctFromText(txt) :\n",
    "    \"Returns a list [(nShares, percent) ... ] parsed from form 13G or 13D.\"\n",
    "    for pat in form13NshAndPctPats :\n",
    "        res = pat.findall(txt)\n",
    "        if res :\n",
    "            break\n",
    "    return res\n",
    "\n",
    "purposePat = re.compile(r'4\\s*\\.?\\s*purpose\\s*of\\s*(?:the\\s*)?transaction(?:\\s*\\.?\\s*)(.{1,10000}?)'\n",
    "                        + r'(?:\\s*(?:item\\s*)?5\\s*\\.?\\s*interest'\n",
    "                            + r'|\\s*(?:item\\s*)?6\\s*\\.?\\s*contracts'\n",
    "                            + r'|\\s*(?:item\\s*)?7\\s*\\.?\\s*material'\n",
    "                            + r'|\\s*after\\s*reasonable\\s*inquiry'\n",
    "                            + r'|\\s*$'\n",
    "                        + r')',\n",
    "                        re.IGNORECASE|re.DOTALL)\n",
    "\n",
    "def cusipChecksum(cusip) :\n",
    "    s = 0\n",
    "    for i,c in enumerate(cusip[:8]) :\n",
    "        if c.isdigit() :\n",
    "            v = ord(c) - ord('0')\n",
    "        elif c.isalpha() :\n",
    "            v = 10 + ord(c.upper()) - ord('A')\n",
    "        if (i&1) == 1 :\n",
    "            v *= 2\n",
    "        s += (v//10) + (v%10)\n",
    "    return str((10 - (s%10)) % 10)\n",
    "\n",
    "strictCusipPatStr = r'[\\dA-Z]\\d[\\dA-Z]\\d[\\dA-Z]{4}\\d'\n",
    "cusipPatStr = (r'[\\dA-Z]\\d[\\dA-Z][-_\\s]*\\d[-_\\s]*[\\dA-Z][-_\\s]*[\\dA-Z]'\n",
    "                + r'(?:[-_\\s]*[\\dA-Z]{2}(?:[-_\\s]*\\d)?)?')\n",
    "cusipNumberPatStr = r'cusip\\s*(?:number|#|no)'\n",
    "cusipSearchPats = [re.compile(patStr, re.IGNORECASE|re.DOTALL) for patStr in [\n",
    "    r'.{1,3000}?[^\\dA-Z](' + cusipPatStr + r')[^2-9A-Z]{0,200}?\\s*' + cusipNumberPatStr,\n",
    "    r'.{1,3000}?\\s*' + cusipNumberPatStr + r'[^\\dA-Z]{0,200}?(' + cusipPatStr + r')[^\\dA-Z]',\n",
    "    r'.{1,2000}?\\s(' + strictCusipPatStr + r')\\s',\n",
    "]]\n",
    "spaceDashPat = re.compile(r'[-\\s]*')\n",
    "\n",
    "monthNames = ['January', 'February', 'March', 'April', 'May', 'June',\n",
    "              'July', 'August', 'September', 'October', 'November', 'December']\n",
    "monthAbbrevStrs = ''.join(monthName[:3].lower() for monthName in monthNames)\n",
    "def monthNameToIso(monthName) :\n",
    "    return str(1+(monthAbbrevStrs.find(monthName[:3].lower())//3)).zfill(2)\n",
    "def getMonthPatStr() :\n",
    "    monthNamePatStrs = []\n",
    "    for monthName in monthNames :\n",
    "        monthNamePatStr = monthName[:3]\n",
    "        if monthName != 'May' :\n",
    "            monthNamePatStr += r'(?:'\n",
    "            if monthName == 'September' :\n",
    "                monthNamePatStr += r't|t\\.|'\n",
    "            monthNamePatStr += monthName[3:]\n",
    "            monthNamePatStr += r'|\\.)?'\n",
    "        monthNamePatStrs.append(monthNamePatStr)\n",
    "    return '(' + '|'.join(monthNamePatStrs) + ')'\n",
    "monthPatStr = getMonthPatStr()\n",
    "monthDayPatStr = r'(\\d\\d?)(?:\\s*th|\\s*st)?'\n",
    "possCommaPatStr = r'[.,\\s]'\n",
    "yearPatStr = r'(\\d\\d\\s*\\d\\d)'\n",
    "dateOfEventPatStr = r'dates?\\s*of(?:\\s*the)?\\s*events?\\s*which'\n",
    "dateOfEventAtStartPatStr = r'.{1,3000}?'+dateOfEventPatStr+r'.{0,120}?'\n",
    "dateOfEventAtEndPatStr = r'[^\\d].{0,120}?'+dateOfEventPatStr\n",
    "dateOfEventMonthPat1 = re.compile(r'.{1,3000}?[^\\dA-Z]'\n",
    "                                  + r'\\s*'.join([monthPatStr,monthDayPatStr,possCommaPatStr,yearPatStr])\n",
    "                                  + dateOfEventAtEndPatStr,\n",
    "                                  re.IGNORECASE|re.DOTALL)\n",
    "dateOfEventMonthRevPat1 = re.compile(dateOfEventAtStartPatStr + r'[^\\dA-Z]'\n",
    "                                     + r'\\s*'.join([monthPatStr,monthDayPatStr,possCommaPatStr,yearPatStr])\n",
    "                                     + r'[^\\d]',\n",
    "                                     re.IGNORECASE|re.DOTALL)\n",
    "dateOfEventMonthPat2 = re.compile(r'.{1,3000}?[^\\d]'\n",
    "                                  + r'\\s*'.join([monthDayPatStr,monthPatStr,possCommaPatStr,yearPatStr])\n",
    "                                  + dateOfEventAtEndPatStr,\n",
    "                                  re.IGNORECASE|re.DOTALL)\n",
    "dateOfEventMonthRevPat2 = re.compile(dateOfEventAtStartPatStr + r'[^\\d]'\n",
    "                                     + r'\\s*'.join([monthDayPatStr,monthPatStr,possCommaPatStr,yearPatStr])\n",
    "                                     + r'[^\\d]',\n",
    "                                     re.IGNORECASE|re.DOTALL)\n",
    "isoSepPatStr = r'\\s*[-/]\\s*'\n",
    "dateOfEventIsoPat1 = re.compile(r'.{1,3000}?[^\\d]'\n",
    "                                + isoSepPatStr.join([r'(\\d\\d?)',r'(\\d\\d?)',r'(\\d\\d(?:\\d\\d)?)'])\n",
    "                                + dateOfEventAtEndPatStr,\n",
    "                                re.IGNORECASE|re.DOTALL)\n",
    "dateOfEventIsoRevPat1 = re.compile(dateOfEventAtStartPatStr + r'[^\\d]'\n",
    "                                   + isoSepPatStr.join([r'(\\d\\d?)',r'(\\d\\d?)',r'(\\d\\d(?:\\d\\d)?)'])\n",
    "                                   + r'[^\\d]',\n",
    "                                   re.IGNORECASE|re.DOTALL)\n",
    "dateOfEventIsoPat2 = re.compile(r'.{1,3000}?[^\\d]'\n",
    "                                + isoSepPatStr.join([r'(\\d\\d\\d\\d)',r'(\\d\\d?)',r'(\\d\\d?)'])\n",
    "                                + dateOfEventAtEndPatStr,\n",
    "                                re.IGNORECASE|re.DOTALL)\n",
    "dateOfEventIsoRevPat2 = re.compile(dateOfEventAtStartPatStr + r'[^\\d]'\n",
    "                                   + isoSepPatStr.join([r'(\\d\\d\\d\\d)',r'(\\d\\d?)',r'(\\d\\d?)'])\n",
    "                                   + r'[^\\d]',\n",
    "                                   re.IGNORECASE|re.DOTALL)\n",
    "whitespacePat = re.compile(r'\\s*',re.IGNORECASE|re.DOTALL)\n",
    "def parseEventDate(info,mainText) :\n",
    "    m = dateOfEventMonthPat1.match(mainText) or dateOfEventMonthRevPat1.match(mainText)\n",
    "    if m :\n",
    "        info['eventDate'] = '-'.join([whitespacePat.sub('',m.group(3)),\n",
    "                                      monthNameToIso(m.group(1)),m.group(2).zfill(2)])\n",
    "        return\n",
    "    m = dateOfEventMonthPat2.match(mainText) or dateOfEventMonthRevPat2.match(mainText)\n",
    "    if m :\n",
    "        info['eventDate'] = '-'.join([whitespacePat.sub('',m.group(3)),\n",
    "                                      monthNameToIso(m.group(2)),m.group(1).zfill(2)])\n",
    "        return\n",
    "    m = dateOfEventIsoPat1.match(mainText) or dateOfEventIsoRevPat1.match(mainText)\n",
    "    if m :\n",
    "        info['eventDate'] = '-'.join([('20' if len(m.group(3))==2 else '')+m.group(3),\n",
    "                                      m.group(1).zfill(2),m.group(2).zfill(2)])\n",
    "        return\n",
    "    m = dateOfEventIsoPat2.match(mainText) or dateOfEventIsoRevPat2.match(mainText)\n",
    "    if m :\n",
    "        info['eventDate'] = '-'.join([m.group(1),m.group(2).zfill(2),m.group(3).zfill(2)])\n",
    "        return\n",
    "    print('NO EVENT DATE!')\n",
    "\n",
    "\n",
    "def parse13GD(accNo, formType=None) :\n",
    "    info = basicInfo.getSecFormInfo(accNo, formType=formType)\n",
    "    if 'filedByCik' not in info :\n",
    "        print('No filed by CIK!')\n",
    "    links = info['links']\n",
    "    if len(links) == 0 :\n",
    "        print('NO LINKS LIST!')\n",
    "        info['positions'] = []\n",
    "    else :\n",
    "        toFormat = 'text' if links[0][3].endswith('.txt') else 'souptext'\n",
    "        mainText = utils.downloadSecUrl(links[0][3], toFormat=toFormat)\n",
    "        parseEventDate(info,mainText)\n",
    "        info['positions'] = getSec13NshAndPctFromText(mainText)\n",
    "        for cusipSearchPat in cusipSearchPats :\n",
    "            m = cusipSearchPat.match(mainText)\n",
    "            if m is not None :\n",
    "                break\n",
    "        if m is None :\n",
    "            if not ('0001504304' in info['ciks'] or '0001067621' in info['ciks']) :\n",
    "                # suppress the message for 0001504304 - Bulldog Investors\n",
    "                # and 0001067621 - Phillip Goldstein\n",
    "                # - they don't report CUSIPs in their filings\n",
    "                print('no CUSIP found!')\n",
    "        else :\n",
    "            cusip = spaceDashPat.sub('',m.group(1))\n",
    "            if len(cusip) == 6 :\n",
    "                print('adding 10 to CUSIP', cusip, end=' ')\n",
    "                cusip = cusip + '10'\n",
    "            if len(cusip) == 8 :\n",
    "                print('adding checksum to CUSIP', cusip)\n",
    "                if cusipChecksum('0'+cusip[:7]) == cusip[7] :\n",
    "                    cusip = '0'+cusip\n",
    "                else :\n",
    "                    cusip = cusip + cusipChecksum(cusip)\n",
    "            if len(cusip)!=9 or cusip[8]!=cusipChecksum(cusip) :\n",
    "                print('invalid CUSIP!',cusip)\n",
    "            info['cusip'] = cusip.upper()\n",
    "            # print('CUSIP-'+cusip,end=' ')\n",
    "        if formType is None :\n",
    "            formType = links[0][2]\n",
    "        if formType.upper().startswith('SC 13D') :\n",
    "            m = purposePat.search(mainText)\n",
    "            if m is None :\n",
    "                print('no purpose!', end=' ')\n",
    "            else :\n",
    "                info['purpose'] = m.group(1)\n",
    "    if len(info['positions']) == 0 :\n",
    "        print('no positions found!')\n",
    "    return info #,mainText\n",
    "\n",
    "class scraper13G(infoScraper.scraperBase) :\n",
    "    def __init__(self, infoDir=default13GDir, startD=None, endD=None, fSuff='m.pkl', **pickle_kwargs) :\n",
    "        super().__init__(infoDir, 'SC 13G', startD=startD, endD=endD, fSuff=fSuff, **pickle_kwargs)\n",
    "    def scrapeInfo(self, accNo, formType=None) :\n",
    "        return parse13GD(accNo, formType=formType), None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test 13G scraper class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20210703 WEEKEND 20210702 ### list index 39 filings for 20210702: 6569 * 20210701 filings for 20210701: 5573 * "
     ]
    }
   ],
   "source": [
    "dl = dailyList.dailyList(startD='empty')\n",
    "dl.updateForDays('20210701','20210704')\n",
    "assert len(dl.getFilingsList(None,'SC 13G')[0])==100,\"testing 13G scraper class (daily list count)\"\n",
    "info = parse13GD('0001567619-21-013814', formType='SC 13G')\n",
    "assert (info['ciks']==['0000016099', '0001373604']\n",
    "        and info['positions']==[('1350552', '4.36'), ('1582235', '5.10')]\n",
    "        and info['cusip']=='549282101'\n",
    "    ),\"testing 13G scraper class (parsing)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate or update a combined map of CIK 13G and 13D positions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def updateCik13GDPos(scrapers, cik13GDPosMap=None) :\n",
    "    \"\"\"\n",
    "    Generate or update a combined dict of percentage holdings:\n",
    "        cik13GDPosMap: cik -> {cusip -> (eventDate, accNo, pct)}\n",
    "    based on a list of 13G and 13D scrapers.\n",
    "    \"\"\"\n",
    "    if cik13GDPosMap is None :\n",
    "        cik13GDPosMap = collections.defaultdict(dict)\n",
    "    cikTo13GDs = collections.defaultdict(list)\n",
    "    count = 0\n",
    "    for scraper in scrapers :\n",
    "        for dStr, accNoToInfo in scraper.infoMap.items() :\n",
    "            for accNo, info in accNoToInfo.items() :\n",
    "                if info == 'ERROR' :\n",
    "                    print('*** ERROR in ',accNo)\n",
    "                elif 'filedByCik' not in info :\n",
    "                    print('*** No filed-by CIK in',accNo)\n",
    "                elif 'cusip' not in info :\n",
    "                    print('No CUSIP in',accNo)\n",
    "                elif len(info['positions']) == 0 :\n",
    "                    print('*** No positions found in',accNo)\n",
    "                else :\n",
    "                    if 'eventDate' not in info :\n",
    "                        eventDate = (utils.toDate(dStr)-datetime.timedelta(7)).isoformat()\n",
    "                        print(f'No event date in {accNo}; using {eventDate}')\n",
    "                    else :\n",
    "                        eventDate = info['eventDate']\n",
    "                    cikTo13GDs[info['filedByCik'].lstrip('0')].append(\n",
    "                        (info['cusip'], eventDate, accNo, max(float(pct) for _,pct in info['positions'])))\n",
    "                    count += 1\n",
    "    print('total of',len(cikTo13GDs),'ciks,',count,'13G/D filings')\n",
    "    for cik, cik13GDList in cikTo13GDs.items() :\n",
    "        posMap = cik13GDPosMap[cik]\n",
    "        for tup in cik13GDList :\n",
    "            cusip = tup[0]\n",
    "            if cusip not in posMap or posMap[cusip] < tup[1:] :\n",
    "                posMap[cusip] = tup[1:]\n",
    "    return cik13GDPosMap\n",
    "\n",
    "def calcBonusMap(cik13GDPosMap, max13GDBonus=0.2, min13GDBonus=0.02, max13GDCount=100) :\n",
    "    \"\"\"\n",
    "    Calculate \"bonus fractions\" for cusips where a 13G or 13D has been filed.\n",
    "\n",
    "    Returns a dict: cik -> {cusip -> bonusfrac}\n",
    "    \"\"\"\n",
    "    res = {}\n",
    "    for cik,posMap in cik13GDPosMap.items() :\n",
    "        cusips = [cusip for cusip,pos in posMap.items()\n",
    "                  if pos[-1] >= 5.0]\n",
    "        # Don't give a bonus for positions below 5% because this often means\n",
    "        # they're in the process of selling off the whole position.\n",
    "        if len(cusips) > 0 :\n",
    "            bonus = min(max13GDBonus,max(min13GDBonus,1/len(cusips)))\n",
    "            res[cik] = dict((cusip,bonus) for cusip in cusips)\n",
    "    if max13GDCount is not None :\n",
    "        res = dict((cik,posMap) for cik,posMap in res.items() if len(posMap)<=max13GDCount)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test generating and updating a combined map of CIK 13G and 13D positions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========NEW 20210701========== '0001104659-21-088227' '0001104659-21-088230' total of 1 ciks, 2 13G/D filings\n",
      "==========NEW 20210703========== ==========NEW 20210702========== '0001104659-21-088828' '0001104659-21-088837' total of 1 ciks, 2 13G/D filings\n"
     ]
    }
   ],
   "source": [
    "s = scraper13G(startD='empty')\n",
    "s.updateForDays(dl,ciks=['1423053'],startD='20210701',endD='20210702')\n",
    "ss = updateCik13GDPos([s])\n",
    "assert ss['1423053'] == {\n",
    "    '265334102': ('2021-06-21', '0001104659-21-088227', 8.2),\n",
    "    'G2426E112': ('2021-06-21', '0001104659-21-088230', 6.5)\n",
    "}\n",
    "\n",
    "s = scraper13G(startD='empty')\n",
    "s.updateForDays(dl,ciks=['1423053'],startD='20210702',endD='20210704')\n",
    "ss = updateCik13GDPos([s],ss)\n",
    "assert ss['1423053'] == {\n",
    "    '265334102': ('2021-06-21', '0001104659-21-088227', 8.2),\n",
    "    'G2426E112': ('2021-06-21', '0001104659-21-088230', 6.5),\n",
    "    '88408P107': ('2021-06-22', '0001104659-21-088828', 7.9),\n",
    "    '36118N102': ('2021-06-22', '0001104659-21-088837', 6.5)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# dailyList.dlCountFilings(startD='20210101',formClass='SC 13G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# uncomment and run to regenerate all library Python files\n",
    "# from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
