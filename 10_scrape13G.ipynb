{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp scrape13G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scrape13G\n",
    "\n",
    "> Scrape holdings information from 13G SEC filings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from nbdev import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import collections\n",
    "import datetime\n",
    "import itertools\n",
    "import os\n",
    "import re\n",
    "\n",
    "from secscan import utils, dailyList, basicInfo, infoScraper\n",
    "\n",
    "default13GDir = os.path.join(utils.stockDataRoot,'scraped13G')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13G scraper class - scrape holdings information from the SEC filing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "reOPTS = re.IGNORECASE|re.DOTALL\n",
    "# aggregatePatStr = r'aggregate.?\\s+amount\\s+(?:ben|own)'\n",
    "# percentOfClassPatStr = r'percent\\s+(?:of|or)\\s+class\\s+(?:re|pr)'\n",
    "# typeOfRepPatStr = r'type.?\\s+(?:of|or)\\s+(?:rep|per)'\n",
    "aggregatePatStr = r'aggregated?\\s+amount\\s+ben'\n",
    "percentOfClassPatStr = r'percent(?:age)?\\s+of\\s+class\\s+(?:re|pr)'\n",
    "typeOfRepPatStr = r'type\\s+of\\s+(?:rep|per)'\n",
    "item9PatStr,item11PatStr,item12PatStr,item13PatStr,item14PatStr = (\n",
    "    r'item\\s+' + itemNo + r'\\s*:' for itemNo in ('9','11','12','13','14'))\n",
    "form13PiecesPat1 = re.compile(r'.*?'.join([aggregatePatStr,percentOfClassPatStr,typeOfRepPatStr]),reOPTS)\n",
    "form13PiecesPat2 = re.compile(r'.*?'.join([item9PatStr,item11PatStr,item12PatStr]),reOPTS)\n",
    "form13PiecesPat3 = re.compile(r'.*?'.join([item11PatStr,item13PatStr,item14PatStr]),reOPTS)\n",
    "# nSharesPatStr = r'\\D(?!9\\s|9\\D\\D)(\\d+(?:[,.]\\d\\d\\d)*)' # try to avoid taking item number 9 as share count\n",
    "nSharesPatStr = r'(?<!\\d)(?!9\\s|9\\D\\D)(\\d+[,.\\d]*)' # try to avoid taking item number 9 as share count\n",
    "nPctBarePatStr = r'(\\d+(?:\\.\\d*)?|\\.\\d+)'\n",
    "nPctWithPctPatStr = r'((?:\\d+(?:[\\.,]\\d*)?|[\\.,]\\d+)\\s*%)'\n",
    "nshAndPctPat1Pref = r'.*?'.join([aggregatePatStr,nSharesPatStr,percentOfClassPatStr])\n",
    "form13NshAndPctPats1 = [\n",
    "    re.compile(r'.*?'.join([nshAndPctPat1Pref,nPctWithPctPatStr,typeOfRepPatStr]),reOPTS),\n",
    "    # if percentage isn't followed by a % character, look for a plain number but\n",
    "    # try to avoid using the 9 in \"mentioned in item 9\" verbiage for the percentage\n",
    "    re.compile(r'.*?'.join([nshAndPctPat1Pref,r'\\D9(?!\\.\\d)\\D.*?'+nPctBarePatStr,typeOfRepPatStr]),reOPTS),\n",
    "    # ditto for \"mentioned in item 11\" verbiage\n",
    "    re.compile(r'.*?'.join([nshAndPctPat1Pref,r'\\D11(?!\\.\\d)\\D.*?'+nPctBarePatStr,typeOfRepPatStr]),reOPTS),\n",
    "    re.compile(r'.*?'.join([nshAndPctPat1Pref,nPctBarePatStr,typeOfRepPatStr]),reOPTS)\n",
    "]\n",
    "form13NshAndPctPat2 = re.compile(r'.*?'.join([item9PatStr,nSharesPatStr,item11PatStr,\n",
    "                                              nPctWithPctPatStr,item12PatStr]), reOPTS)\n",
    "form13NshAndPctPat3 = re.compile(r'.*?'.join([item11PatStr,nSharesPatStr,item13PatStr,\n",
    "                                              nPctWithPctPatStr,item14PatStr]), reOPTS)\n",
    "def getSec13NshAndPctFromText2(txt,accNo, debug=False) :\n",
    "    \"Returns a list [(nShares, percent) ... ] parsed from form 13G or 13D.\"\n",
    "    if debug : print(txt)\n",
    "    res = []\n",
    "    pat1Pieces = form13PiecesPat1.findall(txt)\n",
    "    for piece in pat1Pieces :\n",
    "        if debug : print('********1',piece)\n",
    "        if not any(addNshAndPct(pat.match(piece),res) for pat in form13NshAndPctPats1) :\n",
    "            print(\"??????1\", accNo, piece)\n",
    "    if res :\n",
    "        return res\n",
    "    pat2Pieces = form13PiecesPat2.findall(txt)\n",
    "    for piece in pat2Pieces :\n",
    "        if debug : print('********2',piece)\n",
    "        if not addNshAndPct(form13NshAndPctPat2.match(piece),res) :\n",
    "            print(\"??????2\", accNo, piece)\n",
    "    if res :\n",
    "        return res\n",
    "    pat3Pieces = form13PiecesPat3.findall(txt)\n",
    "    for piece in pat3Pieces :\n",
    "        if debug : print('********3',piece)\n",
    "        if not addNshAndPct(form13NshAndPctPat3.match(piece),res) :\n",
    "            print(\"??????3\", accNo, piece)\n",
    "    return res\n",
    "def addNshAndPct(m,res) :\n",
    "    if not m :\n",
    "        return False\n",
    "    # print(m.groups())\n",
    "    nSh,pct = m.groups()\n",
    "    if nSh in ['10','10.','11','11.','12','12.'] :\n",
    "        nSh = '999'\n",
    "    if pct in ['9','9.','11','11.','12','12.','14','14.'] :\n",
    "        return False\n",
    "    # nSh = nSh.replace('.',',')\n",
    "    pct = pct.replace(',','.').replace('%','').rstrip()\n",
    "    res.append((nSh,pct))\n",
    "    return True\n",
    "\n",
    "purposePat = re.compile(r'4\\s*\\.?\\s*purpose\\s*of\\s*(?:the\\s*)?transaction(?:\\s*\\.?\\s*)(.{1,20000}?)'\n",
    "                        + r'(?:\\s*(?:item\\s*)?5\\s*\\.?\\s*interest'\n",
    "                            + r'|\\s*(?:item\\s*)?6\\s*\\.?\\s*contracts'\n",
    "                            + r'|\\s*(?:item\\s*)?7\\s*\\.?\\s*material'\n",
    "                            + r'|\\s*after\\s*reasonable\\s*inquiry'\n",
    "                            + r'|\\s*$'\n",
    "                        + r')', reOPTS)\n",
    "\n",
    "def cusipChecksum(cusip) :\n",
    "    s = 0\n",
    "    for i,c in enumerate(cusip[:8]) :\n",
    "        if c.isdigit() :\n",
    "            v = ord(c) - ord('0')\n",
    "        elif c.isalpha() :\n",
    "            v = 10 + ord(c.upper()) - ord('A')\n",
    "        if (i&1) == 1 :\n",
    "            v *= 2\n",
    "        s += (v//10) + (v%10)\n",
    "    return str((10 - (s%10)) % 10)\n",
    "\n",
    "strictCusipPatStr = r'[\\dA-Z]\\d[\\dA-Z]\\d[\\dA-Z]{4}\\d'\n",
    "cusipPatStr = (r'[\\dA-Z]\\d[\\dA-Z][-_\\s]*\\d[-_\\s]*[\\dA-Z][-_\\s]*[\\dA-Z]'\n",
    "                + r'(?:[-_\\s]*[\\dA-Z]{2}(?:[-_\\s]*\\d)?)?')\n",
    "cusipNumberPatStr = r'cusip\\s*(?:number|#|no)'\n",
    "cusipSearchPats = [re.compile(patStr, reOPTS) for patStr in [\n",
    "    r'.{1,3000}?[^\\dA-Z](' + cusipPatStr + r')[^2-9A-Z]{0,200}?\\s*' + cusipNumberPatStr,\n",
    "    r'.{1,3000}?\\s*' + cusipNumberPatStr + r'[^\\dA-Z]{0,200}?(' + cusipPatStr + r')[^\\dA-Z]',\n",
    "    r'.{1,2000}?\\s(' + strictCusipPatStr + r')\\s',\n",
    "]]\n",
    "spaceDashPat = re.compile(r'[-\\s]*')\n",
    "\n",
    "monthNames = ['January', 'February', 'March', 'April', 'May', 'June',\n",
    "              'July', 'August', 'September', 'October', 'November', 'December']\n",
    "monthAbbrevStrs = ''.join(monthName[:3].lower() for monthName in monthNames)\n",
    "def monthNameToIso(monthName) :\n",
    "    return str(1+(monthAbbrevStrs.find(monthName[:3].lower())//3)).zfill(2)\n",
    "def getMonthPatStr() :\n",
    "    monthNamePatStrs = []\n",
    "    for monthName in monthNames :\n",
    "        monthNamePatStr = monthName[:3]\n",
    "        if monthName != 'May' :\n",
    "            monthNamePatStr += r'(?:'\n",
    "            if monthName == 'September' :\n",
    "                monthNamePatStr += r't|t\\.|'\n",
    "            monthNamePatStr += monthName[3:]\n",
    "            monthNamePatStr += r'|\\.)?'\n",
    "        monthNamePatStrs.append(monthNamePatStr)\n",
    "    return '(' + '|'.join(monthNamePatStrs) + ')'\n",
    "monthPatStr = getMonthPatStr()\n",
    "monthDayPatStr = r'(\\d\\d?)(?:\\s*th|\\s*st)?'\n",
    "possCommaPatStr = r'[.,\\s]'\n",
    "yearPatStr = r'(\\d\\d\\s*\\d\\d)'\n",
    "dateOfEventPatStr = r'dates?\\s*of(?:\\s*the)?\\s*events?\\s*which'\n",
    "dateOfEventAtStartPatStr = r'.{1,3000}?'+dateOfEventPatStr+r'.{0,120}?'\n",
    "dateOfEventAtEndPatStr = r'[^\\d].{0,120}?'+dateOfEventPatStr\n",
    "dateOfEventMonthPat1 = re.compile(r'.{1,3000}?[^\\dA-Z]'\n",
    "                                  + r'\\s*'.join([monthPatStr,monthDayPatStr,possCommaPatStr,yearPatStr])\n",
    "                                  + dateOfEventAtEndPatStr, reOPTS)\n",
    "dateOfEventMonthRevPat1 = re.compile(dateOfEventAtStartPatStr + r'[^\\dA-Z]'\n",
    "                                     + r'\\s*'.join([monthPatStr,monthDayPatStr,possCommaPatStr,yearPatStr])\n",
    "                                     + r'[^\\d]', reOPTS)\n",
    "dateOfEventMonthPat2 = re.compile(r'.{1,3000}?[^\\d]'\n",
    "                                  + r'\\s*'.join([monthDayPatStr,monthPatStr,possCommaPatStr,yearPatStr])\n",
    "                                  + dateOfEventAtEndPatStr, reOPTS)\n",
    "dateOfEventMonthRevPat2 = re.compile(dateOfEventAtStartPatStr + r'[^\\d]'\n",
    "                                     + r'\\s*'.join([monthDayPatStr,monthPatStr,possCommaPatStr,yearPatStr])\n",
    "                                     + r'[^\\d]', reOPTS)\n",
    "isoSepPatStr = r'\\s*[-/]\\s*'\n",
    "dateOfEventIsoPat1 = re.compile(r'.{1,3000}?[^\\d]'\n",
    "                                + isoSepPatStr.join([r'(\\d\\d?)',r'(\\d\\d?)',r'(\\d\\d(?:\\d\\d)?)'])\n",
    "                                + dateOfEventAtEndPatStr, reOPTS)\n",
    "dateOfEventIsoRevPat1 = re.compile(dateOfEventAtStartPatStr + r'[^\\d]'\n",
    "                                   + isoSepPatStr.join([r'(\\d\\d?)',r'(\\d\\d?)',r'(\\d\\d(?:\\d\\d)?)'])\n",
    "                                   + r'[^\\d]', reOPTS)\n",
    "dateOfEventIsoPat2 = re.compile(r'.{1,3000}?[^\\d]'\n",
    "                                + isoSepPatStr.join([r'(\\d\\d\\d\\d)',r'(\\d\\d?)',r'(\\d\\d?)'])\n",
    "                                + dateOfEventAtEndPatStr, reOPTS)\n",
    "dateOfEventIsoRevPat2 = re.compile(dateOfEventAtStartPatStr + r'[^\\d]'\n",
    "                                   + isoSepPatStr.join([r'(\\d\\d\\d\\d)',r'(\\d\\d?)',r'(\\d\\d?)'])\n",
    "                                   + r'[^\\d]', reOPTS)\n",
    "whitespacePat = re.compile(r'\\s*', reOPTS)\n",
    "def parseEventDate(info,mainText) :\n",
    "    m = dateOfEventMonthPat1.match(mainText) or dateOfEventMonthRevPat1.match(mainText)\n",
    "    if m :\n",
    "        info['eventDate'] = '-'.join([whitespacePat.sub('',m.group(3)),\n",
    "                                      monthNameToIso(m.group(1)),m.group(2).zfill(2)])\n",
    "        return\n",
    "    m = dateOfEventMonthPat2.match(mainText) or dateOfEventMonthRevPat2.match(mainText)\n",
    "    if m :\n",
    "        info['eventDate'] = '-'.join([whitespacePat.sub('',m.group(3)),\n",
    "                                      monthNameToIso(m.group(2)),m.group(1).zfill(2)])\n",
    "        return\n",
    "    m = dateOfEventIsoPat1.match(mainText) or dateOfEventIsoRevPat1.match(mainText)\n",
    "    if m :\n",
    "        info['eventDate'] = '-'.join([('20' if len(m.group(3))==2 else '')+m.group(3),\n",
    "                                      m.group(1).zfill(2),m.group(2).zfill(2)])\n",
    "        return\n",
    "    m = dateOfEventIsoPat2.match(mainText) or dateOfEventIsoRevPat2.match(mainText)\n",
    "    if m :\n",
    "        info['eventDate'] = '-'.join([m.group(1),m.group(2).zfill(2),m.group(3).zfill(2)])\n",
    "        return\n",
    "    print('NO EVENT DATE!', end=' ')\n",
    "\n",
    "\n",
    "def parse13GD(accNo, formType=None, info=None, textLimit=basicInfo.defaultTextLimit, debug=False) :\n",
    "    if info is None :\n",
    "        info = basicInfo.getSecFormInfo(accNo, formType=formType)\n",
    "    if 'filedByCik' not in info :\n",
    "        print('No filed by CIK!', end=' ')\n",
    "    links = info['links']\n",
    "    if len(links) == 0 :\n",
    "        print('NO LINKS LIST!', end=' ')\n",
    "        info['positions'] = []\n",
    "    else :\n",
    "        toFormat = 'text' if links[0][3].endswith('.txt') else 'souptext'\n",
    "        mainText = utils.downloadSecUrl(links[0][3], toFormat=toFormat)\n",
    "        parseEventDate(info,mainText)\n",
    "        info['positions'] = getSec13NshAndPctFromText2(mainText,accNo, debug=debug)\n",
    "        for cusipSearchPat in cusipSearchPats :\n",
    "            m = cusipSearchPat.match(mainText)\n",
    "            if m is not None :\n",
    "                break\n",
    "        if m is None :\n",
    "            if not ('0001504304' in info['ciks'] or '0001067621' in info['ciks']) :\n",
    "                # suppress the message for 0001504304 - Bulldog Investors\n",
    "                # and 0001067621 - Phillip Goldstein\n",
    "                # - they don't report CUSIPs in their filings\n",
    "                print('no CUSIP found!', end=' ')\n",
    "        else :\n",
    "            cusip = spaceDashPat.sub('',m.group(1))\n",
    "            if len(cusip) == 6 :\n",
    "                print('adding 10 to CUSIP', cusip, end=' ')\n",
    "                cusip = cusip + '10'\n",
    "            if len(cusip) == 8 :\n",
    "                print('adding checksum to CUSIP', cusip, end=' ')\n",
    "                if cusipChecksum('0'+cusip[:7]) == cusip[7] :\n",
    "                    cusip = '0'+cusip\n",
    "                else :\n",
    "                    cusip = cusip + cusipChecksum(cusip)\n",
    "            if len(cusip)!=9 or cusip[8]!=cusipChecksum(cusip) :\n",
    "                print('invalid CUSIP!', cusip, end=' ')\n",
    "            info['cusip'] = cusip.upper()\n",
    "            # print('CUSIP-'+cusip,end=' ')\n",
    "        if formType is None :\n",
    "            formType = links[0][2]\n",
    "        if formType.upper().startswith('SC 13D') :\n",
    "            m = purposePat.search(mainText)\n",
    "            if m is None :\n",
    "                print('no purpose!', end=' ')\n",
    "            else :\n",
    "                info['purpose'] = m.group(1)[:textLimit]\n",
    "    if len(info['positions']) == 0 :\n",
    "        print('no positions found!', end=' ')\n",
    "    return info #,mainText\n",
    "\n",
    "class scraper13G(infoScraper.scraperBase) :\n",
    "    @utils.delegates(infoScraper.scraperBase.__init__)\n",
    "    def __init__(self, infoDir=default13GDir, **kwargs) :\n",
    "        super().__init__(infoDir, 'SC 13G', **kwargs)\n",
    "    def init_for_13D(self, infoDir, **kwargs) :\n",
    "        super().__init__(infoDir, 'SC 13D', **kwargs)\n",
    "    def scrapeInfo(self, accNo, formType=None) :\n",
    "        return parse13GD(accNo, formType=formType), None\n",
    "    def rescrapeInfo(self, accNo, info) :\n",
    "        return parse13GD(accNo, info=info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# accNo = '0000950170-22-000290'\n",
    "# utils.secBrowse(accNo)\n",
    "# parse13GD(accNo)#,debug=True)\n",
    "\n",
    "# uc = utils.requestUrl('https://www.sec.gov/Archives/edgar/data/1737706/000110465921103517/tm2124850d1_sc13g.htm',\n",
    "#                        returnText=True, headers=utils.secHeaders, sleepTime=0.1)\n",
    "# soup = BeautifulSoup(uc,'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test 13G scraper class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20210703 WEEKEND 20210702 ### list index 39 filings for 20210702: 6569 * 20210701 filings for 20210701: 5573 * "
     ]
    }
   ],
   "source": [
    "dl = dailyList.dailyList(startD='empty')\n",
    "dl.updateForDays('20210701','20210704')\n",
    "assert len(dl.getFilingsList(None,'SC 13G')[0])==100,\"testing 13G scraper class (daily list count)\"\n",
    "info = parse13GD('0001567619-21-013814', formType='SC 13G')\n",
    "assert (info['ciks']==['0000016099', '0001373604']\n",
    "        and info['positions']==[('1350552', '4.36'), ('1582235', '5.10')]\n",
    "        and info['cusip']=='549282101'\n",
    "    ),\"testing 13G scraper class (parsing)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate or update a combined map of CIK 13G and 13D positions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def updateCik13GDPos(scraper13G, scraper13D, cik13GDPosMap=None,\n",
    "                     cusipNames=None, cikNames=None, includeTickers=False) :\n",
    "    \"\"\"\n",
    "    Generate or update a combined defaultdict(dict) of percentage holdings:\n",
    "        cik13GDPosMap: cik -> {cusip -> (eventDate, accNo, pct, fType)}\n",
    "    based on scraped filings in scraper13G and scraper13D - pct is in the\n",
    "    range [0.0 .. 100.0], as given in the 13G and 13D filings. For each stock,\n",
    "    finds the latest 13G or 13D filing and keeps the maximum percentage in\n",
    "    that filing. Saves the filing type fType = '13G' or '13D'.\n",
    "\n",
    "    If cusipNames and cikNames are supplied, these should be dicts mapping CUSIP->name\n",
    "    and CIK->name, generated from SEC data. The cusipNames dict will then be modified\n",
    "    to add the corresponding CIK for each CUSIP in a 13G/D filing, since 13G and 13D\n",
    "    filings include both a CUSIP and a corresponding subject CIK. If includeTickers\n",
    "    is True, also adds the ticker symbol based on a CIK to ticker mapping downloaded\n",
    "    from the SEC.\n",
    "    \"\"\"\n",
    "    cusipToCik = None if (cusipNames is None or cikNames is None) else {\n",
    "        # this maps CUSIP -> (latestDateStr, CIK) so the CIK and ticker can be added to cusipNames\n",
    "        # initialize some stocks that don't appear in any 13D or 13G filings:\n",
    "        '931142103' : ('0000-00-00','104169'), # Walmart\n",
    "        '084670108' : ('0000-00-00','1067983'), # Berkshire Hathaway\n",
    "    }\n",
    "    # calculate the latest positions for each CIK based on a list of 13G and 13D scrapers:\n",
    "    #    cik13GDPosMap[cik] = {cusip: (latestDateStr, accNo, maxPctPos), ... }\n",
    "    # also updates cusipToCik to reflect the CUSIP -> CIK correspondence from the scraped filings\n",
    "    if cik13GDPosMap is None :\n",
    "        cik13GDPosMap = collections.defaultdict(dict)\n",
    "    filingCount = 0\n",
    "    for scraper,fType in ((scraper13G,'13G'), (scraper13D,'13D')) :\n",
    "        if scraper is None :\n",
    "            continue\n",
    "        for dStr, accNoToInfo in scraper.infoMap.items() :\n",
    "            for accNo, info in accNoToInfo.items() :\n",
    "                if info == 'ERROR' :\n",
    "                    print('*** ERROR in ',accNo)\n",
    "                elif 'filedByCik' not in info :\n",
    "                    print('*** No filed-by CIK in',accNo)\n",
    "                elif 'cusip' not in info :\n",
    "                    print('No CUSIP in',accNo)\n",
    "                else :\n",
    "                    if len(info['positions']) == 0 :\n",
    "                        print('*** No positions found in',accNo)\n",
    "                        maxPctPos = 0.0\n",
    "                    else :\n",
    "                        maxPctPos = max(float(pct) for _,pct in info['positions'])\n",
    "                    if 'eventDate' not in info :\n",
    "                        eventDate = (utils.toDate(dStr)-datetime.timedelta(7)).isoformat()\n",
    "                        print(f'No event date in {accNo}; using {eventDate}')\n",
    "                    else :\n",
    "                        eventDate = info['eventDate']\n",
    "                    filedByCik = info['filedByCik']\n",
    "                    cusip = info['cusip']\n",
    "                    curPos = (eventDate, accNo, maxPctPos, fType)\n",
    "                    curCikPosMap = cik13GDPosMap[filedByCik.lstrip('0')]\n",
    "                    if cusip not in curCikPosMap or curCikPosMap[cusip] < curPos :\n",
    "                        curCikPosMap[cusip] = curPos\n",
    "                    filingCount += 1\n",
    "                    if cusipToCik is not None :\n",
    "                        subjectCik = [cik for cik in info['ciks'] if cik!=filedByCik]\n",
    "                        if len(subjectCik) != 1 :\n",
    "                            print(f\"missing or ambiguous subject CIK '{accNo}'\")\n",
    "                        elif cusip not in cusipToCik or cusipToCik[cusip][0] < dStr :\n",
    "                            subjectCik = subjectCik[0].lstrip('0')\n",
    "                            if subjectCik in cikNames :\n",
    "                                cusipToCik[cusip] = (dStr, subjectCik)\n",
    "                            else :\n",
    "                                print(f\"subject CIK {subjectCik} name not found '{accNo}'\")\n",
    "    # modify cusipNames to add CIK and ticker symbols:\n",
    "    if cusipToCik is not None :\n",
    "        count1 = count2 = 0\n",
    "        if includeTickers :\n",
    "            cikToTickers = dailyList.getCikToTickersMap()\n",
    "        else :\n",
    "            cikToTickers = collections.defaultdict(list)\n",
    "        # for CUSIPs already in cusipNames, add the corresponding CIK and ticker to the existing entry:\n",
    "        for cusip,name in cusipNames.items() :\n",
    "            if cusip in cusipToCik and 'CIK-' not in name :\n",
    "                _,subjectCik = cusipToCik[cusip]\n",
    "                subjectCikName = cikNames[subjectCik]\n",
    "                # add the CIK name if different from the CUSIP name:\n",
    "                if subjectCikName[:8].strip().lower() != name[:8].strip().lower() :\n",
    "                    cusipNames[cusip] += f' - {subjectCikName}'\n",
    "                # add the CIK and ticker:\n",
    "                cusipNames[cusip] += cikSymStr(subjectCik,cikToTickers[subjectCik])\n",
    "                count1 += 1\n",
    "        # for CUSIPs not in cusipNames, insert a new entry with the CIK name, CIK, and ticker:\n",
    "        for cusip,(_,subjectCik) in cusipToCik.items() :\n",
    "            if cusip not in cusipNames :\n",
    "                cusipNames[cusip] = f'- {cikNames[subjectCik]}{cikSymStr(subjectCik,cikToTickers[subjectCik])}'\n",
    "                count2 += 1\n",
    "        print(f'added CIKS for {count1:,} listed CUSIPs and {count2:,} unlisted CUSIPs')\n",
    "    print(f'total of {len(cik13GDPosMap):,} CIKs with {filingCount:,} 13G/D filings')\n",
    "    return cik13GDPosMap\n",
    "def cikSymStr(cik,tickers) :\n",
    "    return ' (' + ', '.join(sorted(tickers)[:8] + (['...'] if len(tickers)>8 else []) + ['CIK-'+cik])+ ')'\n",
    "\n",
    "def calcBonusMap(cik13GDPosMap, allCusipCounter,\n",
    "                 bonuses = {'13G':[(10.0,0.1), (5.0,0.05)],\n",
    "                            '13D':[(10.0,0.2), (5.0,0.1)],},\n",
    "                 max13GDCount=100) :\n",
    "    \"\"\"\n",
    "    Calculate \"bonus fractions\" for cusips where a 13G or 13D has been filed, using cik13GDPosMap\n",
    "    as calculated by updateCik13GDPos, i.e. a combined defaultdict(dict) of percentage holdings:\n",
    "        cik13GDPosMap: cik -> {cusip -> (eventDate, accNo, pct, fType)}\n",
    "\n",
    "    The bonus fractions are specified separately for 13G and 13D filings using the bonuses dict.\n",
    "\n",
    "    If max13GDCount is not None, restricts to investors with at most max13GDCount combined 13G\n",
    "    and 13D positions.\n",
    "\n",
    "    If allCusipCounter is not None, it should be a Counter and it will be updated to\n",
    "    count all investors that have any nonzero position in each stock.\n",
    "\n",
    "    Returns a dict: cik -> {cusip -> bonusfrac}\n",
    "    \"\"\"\n",
    "    res = {}\n",
    "    for cik,posMap in cik13GDPosMap.items() :\n",
    "        bonusMap = {}\n",
    "        for cusip,pos in posMap.items() :\n",
    "            pct = pos[2]\n",
    "            if pct <= 0.0 :\n",
    "                continue\n",
    "            if allCusipCounter is not None :\n",
    "                allCusipCounter[cusip] += 1\n",
    "            fType = pos[3]\n",
    "            for bonusPct,bonusFrac in bonuses[fType] :\n",
    "                if pct >= bonusPct :\n",
    "                    bonusMap[cusip] = bonusFrac\n",
    "                    break\n",
    "        if len(bonusMap)>0 and (max13GDCount is None or len(bonusMap)<=max13GDCount) :\n",
    "            res[cik] = bonusMap\n",
    "    return res\n",
    "# def calcBonusMap(cik13GDPosMap, allCusipCounter,\n",
    "#                  #bonuses = {'13G':[(10.0,0.1),(5.0,0.05)],\n",
    "#                  #           '13D':[(10.0,0.2),(5.0,0.1)],}\n",
    "#                  max13GDBonus=0.2, min13GDBonus=0.02, max13GDCount=100) :\n",
    "#     \"\"\"\n",
    "#     Calculate \"bonus fractions\" for cusips where a 13G or 13D has been filed, using cik13GDPosMap\n",
    "#     as calculated by updateCik13GDPos, i.e. a combined defaultdict(dict) of percentage holdings:\n",
    "#         cik13GDPosMap: cik -> {cusip -> (eventDate, accNo, pct, fType)}\n",
    "\n",
    "#     13GD bonus fractions are 1.0/#positions, but restricted to [min13GDBonus..max13GDBonus]\n",
    "#     If max13GDCount is not None, restricts to investors with at most max13GDCount combined 13G\n",
    "#     and 13D positions. For positions between [1.0% .. 5.0%), the bonus is cut in half;\n",
    "#     positions below 1.0% aren't given a bonus.\n",
    "\n",
    "#     Returns a dict: cik -> {cusip -> bonusfrac}\n",
    "\n",
    "#     If allCusipCounter is not None, it should be a Counter and it will be updated to\n",
    "#     count all investors that have any position in each stock.\n",
    "#     \"\"\"\n",
    "#     res = {}\n",
    "#     for cik,posMap in cik13GDPosMap.items() :\n",
    "#         fullCusips, halfCusips = [], []\n",
    "#         for cusip,pos in posMap.items() :\n",
    "#             pct = pos[2]\n",
    "#             if pct <= 0.0 :\n",
    "#                 continue\n",
    "#             if allCusipCounter is not None :\n",
    "#                 allCusipCounter[cusip] += 1\n",
    "#             if pct >= 5.0 :\n",
    "#                 fullCusips.append(cusip)\n",
    "#             elif pct >= 1.0 :\n",
    "#                 halfCusips.append(cusip)\n",
    "#         totNCusips = len(fullCusips) + len(halfCusips)\n",
    "#         if totNCusips>0 and (max13GDCount is None or totNCusips<=max13GDCount) :\n",
    "#             bonus = min(max13GDBonus,max(min13GDBonus,1/totNCusips))\n",
    "#             res[cik] = dict((cusip,bonus) for cusip in fullCusips)\n",
    "#             res[cik].update((cusip,bonus*0.5) for cusip in halfCusips)\n",
    "#     return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test generating and updating a combined map of CIK 13G and 13D positions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========NEW 20210701========== '0001104659-21-088227' '0001104659-21-088230' total of 1 ciks, 2 13G/D filings\n",
      "==========NEW 20210703========== ==========NEW 20210702========== '0001104659-21-088828' '0001104659-21-088837' total of 1 ciks, 2 13G/D filings\n"
     ]
    }
   ],
   "source": [
    "s = scraper13G(startD='empty')\n",
    "s.updateForDays(dl,ciks=['1423053'],startD='20210701',endD='20210702')\n",
    "ss = updateCik13GDPos([s])\n",
    "assert ss['1423053'] == {\n",
    "    '265334102': ('2021-06-21', '0001104659-21-088227', 8.2),\n",
    "    'G2426E112': ('2021-06-21', '0001104659-21-088230', 6.5)\n",
    "}\n",
    "\n",
    "s = scraper13G(startD='empty')\n",
    "s.updateForDays(dl,ciks=['1423053'],startD='20210702',endD='20210704')\n",
    "ss = updateCik13GDPos([s],ss)\n",
    "assert ss['1423053'] == {\n",
    "    '265334102': ('2021-06-21', '0001104659-21-088227', 8.2),\n",
    "    'G2426E112': ('2021-06-21', '0001104659-21-088230', 6.5),\n",
    "    '88408P107': ('2021-06-22', '0001104659-21-088828', 7.9),\n",
    "    '36118N102': ('2021-06-22', '0001104659-21-088837', 6.5)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# uncomment and run to regenerate all library Python files\n",
    "# from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
