{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# utils\n",
    "\n",
    "> Assorted low-level utilities for a flexible SEC filings scanner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from nbdev import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "from bs4 import BeautifulSoup, Comment, Doctype, NavigableString\n",
    "import datetime\n",
    "import gzip\n",
    "import inspect\n",
    "from io import BytesIO\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "from pytz import timezone\n",
    "import requests\n",
    "import sys\n",
    "import time\n",
    "import webbrowser\n",
    "import xml.etree.cElementTree as cElTree\n",
    "\n",
    "boto3_available = True\n",
    "try :\n",
    "    import boto3\n",
    "except :\n",
    "    boto3_available = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set directory for scraped data\n",
    "We store all scraped data under stockDataRoot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "stockDataRoot = os.path.expanduser(os.path.join('~','secData'))\n",
    "def setStockDataRoot(loc) :\n",
    "    \"Set location for storing scraped stock data.\"\n",
    "    global stockDataRoot\n",
    "    stockDataRoot = loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low-level download functions\n",
    "We download SEC data using the requests library.\n",
    "We retry a few times in case of a temporary internet glitch,\n",
    "and also recognize an SEC-specific temporary outage message and raise an Exception for it\n",
    "so that we can flag the problem and retry later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def requestUrl(url, timeout=5.0, nTries=5, returnText=False, headers=None, sleepTime=None, **kwargs) :\n",
    "    \"\"\"\n",
    "    Downloads a URL using the requests package.\n",
    "    If sleepTime is not None, sleeps for the given time to stay under max request rate limits.\n",
    "    \"\"\"\n",
    "    for i in range(nTries) :\n",
    "        try :\n",
    "            if sleepTime is not None :\n",
    "                time.sleep(sleepTime)\n",
    "            r = requests.get(url, headers=headers, timeout=timeout, params=kwargs)\n",
    "            r.raise_for_status()\n",
    "            return r.text if returnText else r\n",
    "        except Exception as e :\n",
    "            print('*** Problem','downloading',url,'-',e,'; retrying ...')\n",
    "            if i >= nTries-1 :\n",
    "                print('*** UNABLE TO DOWNLOAD ***')\n",
    "                raise\n",
    "\n",
    "secUrlPref = 'https://www.sec.gov'\n",
    "secRestDataPref = 'https://data.sec.gov'\n",
    "secHeaders = dict(requests.utils.default_headers())\n",
    "def setSecUserAgent(agentStr) :\n",
    "    \"\"\"\n",
    "    Should be used to set user agent to your email address for requests to the SEC site,\n",
    "    to help avoid throttling.\n",
    "    \"\"\"\n",
    "    secHeaders['User-Agent'] = agentStr\n",
    "    #secHeaders['Host'] = 'www.sec.gov'\n",
    "    #secHeaders['Accept-Encoding'] = 'gzip, deflate'\n",
    "setSecUserAgent('secscantest@secscan.com')\n",
    "secSleepTime = 0.1 # sleep time after requests to stay under SEC max request rate (currently 10/sec)\n",
    "sys.setrecursionlimit(2000) # some filings have deeply nested HTML\n",
    "\n",
    "accessNoPatStr = r'\\d{10}-\\d+-\\d+'\n",
    "accessNoPat = re.compile(accessNoPatStr)\n",
    "def secIndexUrl(accessNo, includePref=False) :\n",
    "    \"Returns the url for the index page of an SEC filing specified by accession number.\"\n",
    "    return ((secUrlPref if includePref else '')\n",
    "            + '/Archives/edgar/data/'+accessNo.replace('-','')\n",
    "            +'/'+accessNo+'-index.htm')\n",
    "\n",
    "# from bs4.element import Comment\n",
    "# def tag_visible(element):\n",
    "#     if element.parent.name in ['style', 'script', 'head', 'title', 'meta', '[document]'] :\n",
    "#         return False\n",
    "#     if isinstance(element, Comment):\n",
    "#         return False\n",
    "#     return True\n",
    "# def getCombSoupText(tag) :\n",
    "#     \"Get the combined text from a BeautifulSoup tag.\"\n",
    "#     texts = tag.findAll(text=True)\n",
    "#     texts = filter(tag_visible,texts)\n",
    "#     return u\" \".join(t.strip() for t in texts)\n",
    "spacesPat = re.compile(r'\\s+')\n",
    "# def getCombSoupText(tag) :\n",
    "#     \"Get the combined text from a BeautifulSoup tag.\"\n",
    "#     return spacesPat.sub(\" \",\" \".join(tag.stripped_strings))\n",
    "def appendSpace(resL) :\n",
    "    if resL[-1] != ' ' :\n",
    "        resL.append(' ')\n",
    "tagsWithLeftSpace = tagsWithRightSpace = {'p','br','div','table','tr','td','li','pre','code'}\n",
    "def getCombTextRec(soup, resL) :\n",
    "    if isinstance(soup,Comment) or isinstance(soup,Doctype) :\n",
    "        return\n",
    "    if isinstance(soup,NavigableString) :\n",
    "        s = soup.string.lstrip()\n",
    "        if s != soup.string :\n",
    "            appendSpace(resL)\n",
    "        ss = s.rstrip()\n",
    "        if ss != '' :\n",
    "            resL.append(ss)\n",
    "        if ss != s :\n",
    "            resL.append(' ')\n",
    "        return\n",
    "    if soup.name in tagsWithLeftSpace :\n",
    "        appendSpace(resL)\n",
    "    for c in soup.children :\n",
    "        getCombTextRec(c,resL)\n",
    "    if soup.name in tagsWithRightSpace :\n",
    "        appendSpace(resL)\n",
    "def getCombSoupText(soup) :\n",
    "    resL = [' ']\n",
    "    getCombTextRec(soup,resL)\n",
    "    return spacesPat.sub(\" \",''.join(resL)).strip()\n",
    "\n",
    "def prTree(soup, level=0) :\n",
    "    if isinstance(soup,NavigableString) :\n",
    "        print(level*'|'+('COMMENT' if isinstance(soup,Comment)\n",
    "                         else ('DOCTYPE' if isinstance(soup,Doctype) else 'TEXT')),\n",
    "              repr(soup.string))\n",
    "    else :\n",
    "        print(level*'|'+'TAG'+repr(soup.name))\n",
    "        for c in soup.children :\n",
    "            prTree(c,level+1)\n",
    "def prAllTagNames(soup) :\n",
    "    print(sorted(set(tag.name for tag in soup.descendants)))\n",
    "\n",
    "pageUnavailablePat = re.compile('page is temporarily unavailable',re.IGNORECASE)\n",
    "def downloadSecUrl(secSubUrlOrAccessNo, toFormat='text', sleepTime=0.1, restData=False) :\n",
    "    \"\"\"\n",
    "    Downloads a page from the SEC site. The page can be specified by\n",
    "    a sub-URL (ex. /cgi-bin/browse-edgar?CIK=0000716314&owner=exclude),\n",
    "    or just by an accession number (ex. 0001193125-21-181366), in which\n",
    "    case the index page for that filing is downloaded.\n",
    "\n",
    "    Optionally parses the page contents:\n",
    "    - toFormat=='soup' - parses to a BeautifulSoup object\n",
    "    - toFormat=='souptext' - parses to a BeautifulSoup object, then gets combined text\n",
    "    - toFormat=='json' - parses using json.loads\n",
    "    - toFormat=='xml' - parses using xml.etree.cElementTree.fromstring\n",
    "\n",
    "    SEC-specific behavior:\n",
    "\n",
    "    If sleepTime is not None, sleeps for the given time to stay under\n",
    "    the SEC site's maximum request rate (currently 10 requests/second).\n",
    "\n",
    "    Checks for an SEC-specific temporary outage message, and raises\n",
    "    an Exception if it's detected, so that we can detect the problem\n",
    "    and retry the download later.\n",
    "    \"\"\"\n",
    "    if accessNoPat.match(secSubUrlOrAccessNo) :\n",
    "        secSubUrl = secIndexUrl(secSubUrlOrAccessNo)\n",
    "    else :\n",
    "        secSubUrl = secSubUrlOrAccessNo\n",
    "        if secSubUrl.startswith('/ix?') :\n",
    "            secSubUrl = secSubUrl[secSubUrl.index('/',1):]\n",
    "    fullUrl = (secRestDataPref if restData else secUrlPref) + secSubUrl\n",
    "    urlContents = requestUrl(fullUrl, returnText=True, headers=secHeaders, sleepTime=sleepTime)\n",
    "    if pageUnavailablePat.search(urlContents) :\n",
    "        raise Exception('temporary SEC outage')\n",
    "    if toFormat=='soup' :\n",
    "        return BeautifulSoup(urlContents,'html.parser')\n",
    "    elif toFormat=='souptext' :\n",
    "        return getCombSoupText(BeautifulSoup(urlContents,'html.parser'))\n",
    "    elif toFormat=='json' :\n",
    "        return json.loads(urlContents)\n",
    "    elif toFormat == 'xml' :\n",
    "        return cElTree.fromstring(urlContents)\n",
    "    else :\n",
    "        return urlContents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uc = requestUrl(\"https://www.sec.gov/Archives/edgar/data/1165002/000116500221000068/a2q21earningsrelease.htm\",\n",
    "#                 returnText=True, headers=secHeaders)\n",
    "# prTree(BeautifulSoup(uc,'html.parser'))\n",
    "# getCombSoupText(BeautifulSoup(uc,'html.parser'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test downloading from the SEC website:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = downloadSecUrl('')\n",
    "assert 'securities and exchange' in t.lower(), \"SEC main page download\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accessNo = '0000909108-21-000051'\n",
    "assert accessNoPat.match(accessNo) and not accessNoPat.match(accessNo[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accession number 0000909108-21-000051\n",
      "Company name HTML: <span class=\"companyName\">DIAMOND HILL INVESTMENT GROUP INC (Filer)\n",
      " <acronym title=\"Central Index Key\">CIK</acronym>: <a href=\"/cgi-bin/browse-edgar?CIK=0000909108&amp;action=getcompany\">0000909108 (see all company filings)</a></span>\n",
      "Company name text: DIAMOND HILL INVESTMENT GROUP INC (Filer) CIK: 0000909108 (see all company filings)\n"
     ]
    }
   ],
   "source": [
    "print('Accession number',accessNo)\n",
    "s = downloadSecUrl(accessNo, toFormat='soup')\n",
    "s = s.find('span','companyName')\n",
    "print('Company name HTML:',s)\n",
    "companyName = getCombSoupText(s)\n",
    "print('Company name text:',companyName)\n",
    "assert companyName.lower().startswith('diamond hill'),'Parsing company name from filing index.htm'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `delegates` decorator\n",
    "\n",
    "Cool/useful decorator to avoid having to repeat lists of optional keyword arguments in function signatures and docstrs.\n",
    "\n",
    "Adapted from the original design by Jeremy Howard in https://www.fast.ai/2019/08/06/delegation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def delegates(*toFuncs, keepKwargs=False):\n",
    "    \"\"\"\n",
    "    Decorator to specify that a function delegates to one or more delegated functions.\n",
    "    This will:\n",
    "\n",
    "    - replace `**kwargs` in the delegating function's signature with the combined\n",
    "      keyword arguments from the delegated functions, so that these keyword arguments\n",
    "      are visible using autocomplete in a Jupyter environment\n",
    "\n",
    "    - add the docstrs for the delegated functions to the end of the delegating function's\n",
    "      docstr, so the usage documentation for the delegated functions is also visible.\n",
    "    \"\"\"\n",
    "    def _decorator(fromFunc):\n",
    "        sigFrom = inspect.signature(fromFunc)\n",
    "        # print(sigFrom)\n",
    "        sigFromDict = dict(sigFrom.parameters)\n",
    "        kwargsParam = sigFromDict.pop('kwargs')\n",
    "        delegatedDict = {}\n",
    "        docStrs = []\n",
    "        if fromFunc.__doc__ is not None :\n",
    "            docStrs.append(fromFunc.__doc__)\n",
    "        for toFunc in toFuncs :\n",
    "            argL = []\n",
    "            for name,param in inspect.signature(toFunc).parameters.items() :\n",
    "                if param.default!=inspect.Parameter.empty and name not in sigFromDict :\n",
    "                    delegatedDict[name] = param.replace(kind=inspect.Parameter.KEYWORD_ONLY)\n",
    "                    argL.append(f'{name}={param.default}')\n",
    "            docStrs.append('---')\n",
    "            docStrs.append(f'{toFunc.__qualname__} arguments: ' + ', '.join(argL))\n",
    "            if toFunc.__doc__ is not None :\n",
    "                docStrs.append(toFunc.__doc__)\n",
    "        sigFromDict.update(delegatedDict)\n",
    "        if keepKwargs:\n",
    "            sigFromDict['kwargs'] = kwargsParam\n",
    "        fromFunc.__signature__ = sigFrom.replace(parameters=sigFromDict.values())\n",
    "        # print(fromFunc.__signature__)\n",
    "        fromFunc.__doc__ = '\\n'.join(docStrs)\n",
    "        return fromFunc\n",
    "    return _decorator\n",
    "\n",
    "def callDelegated(toFunc, kwargs, *args, **extraKwargs) :\n",
    "    \"\"\"\n",
    "    Call a delegated function. This needs to be used from within a delegating function\n",
    "    if more than one function was delegated to, in order to select the optional arguments\n",
    "    from kwargs that apply to the delegated function.\n",
    "    \"\"\"\n",
    "    # print('callDelegate',toFunc, kwargs, args, extraKwargs)\n",
    "    delegatedKwargs = {}\n",
    "    for name,param in inspect.signature(toFunc).parameters.items() :\n",
    "        if param.default != inspect.Parameter.empty :\n",
    "            delegatedKwargs[name] = kwargs.get(name, param.default)\n",
    "    delegatedKwargs.update(extraKwargs)\n",
    "    # print(delegatedKwargs)\n",
    "    return toFunc(*args,**delegatedKwargs)\n",
    "\n",
    "def checkDelegated(*toFuncs, **kwargs) :\n",
    "    \"\"\"\n",
    "    Raises an exception if kwargs contains any unexpected keyword arguments not included\n",
    "    in any of the delegated functions toFuncs.\n",
    "    \"\"\"\n",
    "    allKws = set()\n",
    "    for toFunc in toFuncs :\n",
    "        allKws.update(name for name,param in inspect.signature(toFunc).parameters.items()\n",
    "                      if param.default != inspect.Parameter.empty)\n",
    "    for name,val in kwargs.items() :\n",
    "        if name not in allKws :\n",
    "            raise TypeError(f'unexpected keyword argument {name}={val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test delegating to one function:\n",
    "\n",
    "def aaa(bbb, ccc=20, ddd=30) :\n",
    "    \"\"\"\n",
    "    doc for aaa\n",
    "    \"\"\"\n",
    "    return bbb + 2*ccc + 3*ddd\n",
    "\n",
    "@delegates(aaa)\n",
    "def test(a, **kwargs) :\n",
    "    \"\"\"\n",
    "    doc for test\n",
    "    \"\"\"\n",
    "    return a + aaa(3*a, **kwargs)\n",
    "\n",
    "assert (test.__doc__.split()==['doc', 'for', 'test',\n",
    "                               '---', 'aaa', 'arguments:', 'ccc=20,', 'ddd=30', 'doc', 'for', 'aaa']\n",
    "        and test(99) == 99 + 3*99 + 2*20 + 3*30\n",
    "        and test(88, ccc=22, ddd=33) == 88 + 3*88 + 2*22 + 3*33\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test delegating to two functions:\n",
    "\n",
    "def xxx(yyy, zzz, www=100, uuu=200, vvv=300) :\n",
    "    \"\"\"\n",
    "    doc\n",
    "    for xxx\n",
    "    \"\"\"\n",
    "    return yyy + 2*zzz + 3*www + 4*uuu + 5*vvv\n",
    "\n",
    "@delegates(aaa,xxx)\n",
    "def test2(a, **kwargs) :\n",
    "    \"\"\"\n",
    "    doc for test2\n",
    "    \"\"\"\n",
    "    return (callDelegated(aaa, kwargs, a),\n",
    "            callDelegated(xxx, kwargs, a, a*a),\n",
    "            callDelegated(xxx, kwargs, a, a*a, uuu=999))\n",
    "\n",
    "assert (test2.__doc__.split() == ['doc', 'for', 'test2',\n",
    "                                  '---', 'aaa', 'arguments:', 'ccc=20,', 'ddd=30', 'doc', 'for', 'aaa',\n",
    "                                  '---', 'xxx', 'arguments:', 'www=100,', 'uuu=200,', 'vvv=300',\n",
    "                                  'doc', 'for', 'xxx']\n",
    "        and test2(77) == (77 + 2*20 + 3*30,\n",
    "                          77 + 2*77*77 + 3*100 + 4*200 + 5*300,\n",
    "                          77 + 2*77*77 + 3*100 + 4*999 + 5*300)\n",
    "        and test2(77, uuu=654, vvv=876, ccc=55) == (77 + 2*55 + 3*30,\n",
    "                          77 + 2*77*77 + 3*100 + 4*654 + 5*876,\n",
    "                          77 + 2*77*77 + 3*100 + 4*999 + 5*876)\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aa init d=99 kwargs={}\n",
      "a init aa=10 bb=20\n",
      "aa init d=99 kwargs={'bb': 100}\n",
      "a init aa=10 bb=100\n"
     ]
    }
   ],
   "source": [
    "# test using with classes:\n",
    "\n",
    "class a() :\n",
    "    def __init__(self, aa=10, bb=20) :\n",
    "        print(f'a init aa={aa} bb={bb}')\n",
    "        self.x = aa + 2*bb\n",
    "\n",
    "class aa(a) :\n",
    "    @delegates(a.__init__)\n",
    "    def __init__(self, d, **kwargs) :\n",
    "        print(f'aa init d={d} kwargs={kwargs}')\n",
    "        super().__init__(**kwargs)\n",
    "        self.x += 3*d\n",
    "    @delegates(xxx) \n",
    "    def mm(self,**kwargs) :\n",
    "        return self.x + aaa(1000,**kwargs)\n",
    "\n",
    "testaa1 = aa(99)\n",
    "testaa2 = aa(99, bb=100)\n",
    "assert (testaa1.x == 3*99 + 10 + 2*20\n",
    "        and testaa2.x == 3*99 + 10 + 2*100\n",
    "        and testaa2.mm() == testaa2.x + 1000 + 2*20 + 3*30\n",
    "        and testaa2.mm(ccc=50) == testaa2.x + 1000 + 2*50 + 3*30\n",
    "       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low-level functions for storing scraped data\n",
    "We store scraped data in pickled format,\n",
    "either storing an object in a single pickled file\n",
    "or storing a dict by saving one file per key\n",
    "(for example, one file per date).\n",
    "We can optionally use gzip compression (smaller files, but slower to read)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In-memory pickling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def compressGZipBytes(b) :\n",
    "    \"Compress a byte string in-memory using gzip.\"\n",
    "    out = BytesIO()\n",
    "    with gzip.GzipFile(fileobj=out, mode=\"w\") as f:\n",
    "        f.write(b)\n",
    "    return out.getvalue()\n",
    "\n",
    "def decompressGZipBytes(b) :\n",
    "    \"Decompress a byte string in-memory using gzip.\"\n",
    "    inp = BytesIO(b)\n",
    "    with gzip.GzipFile(fileobj=inp, mode=\"r\") as f:\n",
    "        return f.read()\n",
    "\n",
    "@delegates(pickle.dumps)\n",
    "def pickleToBytes(ob, use_gzip=False, **kwargs) :\n",
    "    \"Pickle an object in-memory, optionally using gzip compression.\"\n",
    "    b = pickle.dumps(ob, **kwargs)\n",
    "    if use_gzip :\n",
    "        b = compressGZipBytes(b)\n",
    "    return b\n",
    "\n",
    "@delegates(pickle.loads)\n",
    "def pickleFromBytes(b, use_gzip=False, **kwargs) :\n",
    "    \"Unpickle an object in-memory, optionally using gzip compression.\"\n",
    "    if use_gzip :\n",
    "        b = decompressGZipBytes(b)\n",
    "    return pickle.loads(b, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test in-memory pickling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "rng = random.Random(42)\n",
    "test_rand = dict((f'r{i}', rng.random()) for i in range(10))\n",
    "b = pickleToBytes(test_rand)\n",
    "assert test_rand == pickleFromBytes(b), 'pickling an object to bytes (no compression)'\n",
    "b = pickleToBytes(test_rand, use_gzip=True)\n",
    "assert test_rand == pickleFromBytes(b, use_gzip=True), 'pickling an object to bytes (gzip compression)'\n",
    "b = pickleToBytes(test_rand, use_gzip=True, protocol=2)\n",
    "assert test_rand == pickleFromBytes(b, use_gzip=True), 'pickling an object to bytes (gzip compression)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickled data storage to single files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "@delegates(pickleToBytes)\n",
    "def pickSave(fpath, ob, **kwargs) :\n",
    "    \"Save a pickled object to a file, optionally using gzip compression.\"\n",
    "    with open(fpath, 'wb') as f :\n",
    "        f.write(pickleToBytes(ob, **kwargs))\n",
    "\n",
    "@delegates(pickleFromBytes)\n",
    "def pickLoad(fpath, **kwargs) :\n",
    "    \"Load a pickled object from a file, optionally using gzip compression.\"\n",
    "    with open(fpath, 'rb') as f :\n",
    "        return pickleFromBytes(f.read(), **kwargs)\n",
    "\n",
    "@delegates(pickLoad)\n",
    "def pickLoadIfPath(path_or_ob, **kwargs) :\n",
    "    \"\"\"\n",
    "    If given a path, loads a pickled object from it; otherwise returns\n",
    "    its argument unchanged (assumes it's an already loaded object).\n",
    "    \"\"\"\n",
    "    if isinstance(path_or_ob,str) :\n",
    "        return pickLoad(path_or_ob, **kwargs)\n",
    "    else :\n",
    "        return path_or_ob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test pickled data storage to single files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickSave('test.pkl', test_rand)\n",
    "assert test_rand == pickLoad('test.pkl'), 'pickling an object to a file (no compression)'\n",
    "pickSave('test.pkl', test_rand, use_gzip=True)\n",
    "assert test_rand == pickLoad('test.pkl', use_gzip=True), 'pickling an object to a file (gzip compression)'\n",
    "time.sleep(1)\n",
    "os.unlink('test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickled data storage to S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "@delegates(pickleToBytes)\n",
    "def pickSaveToS3(bucket, key, ob, make_public=False, s3=None, **kwargs) :\n",
    "    \"Save a pickled object to an S3 bucket, optionally using gzip compression.\"\n",
    "    if s3 is None : s3 = boto3.client('s3')\n",
    "    s3Args = dict(Bucket=bucket, Key=key, Body=pickleToBytes(ob, **kwargs))\n",
    "    if make_public :\n",
    "        s3Args['ACL'] = 'public-read'\n",
    "    s3.put_object(**s3Args)\n",
    "\n",
    "@delegates(pickleFromBytes)\n",
    "def pickLoadFromS3(bucket, key, s3=None, **kwargs) :\n",
    "    \"Load a pickled object from an S3 bucket, optionally using gzip compression.\"\n",
    "    if s3 is None : s3 = boto3.client('s3')\n",
    "    obj = s3.get_object(Bucket=bucket, Key=key)\n",
    "    return pickleFromBytes(obj['Body'].read(), **kwargs)\n",
    "\n",
    "@delegates(pickleFromBytes)\n",
    "def pickLoadFromS3Public(bucket, key, **kwargs) :\n",
    "    s3PublicUrl = 'https://'+bucket+'.s3.amazonaws.com/'+key\n",
    "    return pickleFromBytes(requestUrl(s3PublicUrl).content, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing pickled data storage to S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boto3 not available, skipping test\n"
     ]
    }
   ],
   "source": [
    "def testS3Pickle(bucket, key, ob) :\n",
    "    if not boto3_available :\n",
    "        print('boto3 not available, skipping test')\n",
    "        return True\n",
    "    s3 = boto3.client('s3')\n",
    "    s3.delete_object(Bucket=bucket, Key=key)\n",
    "    pickSaveToS3(bucket, key, ob)\n",
    "    if ob != pickLoadFromS3(bucket, key) :\n",
    "        return False\n",
    "    pickSaveToS3(bucket, key, ob, use_gzip=True)\n",
    "    if ob != pickLoadFromS3(bucket, key, use_gzip=True) :\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# change thenycentral to your S3 bucket name and set up boto3 to run the test\n",
    "assert testS3Pickle('thenycentral', 'test_rand.pkl', test_rand), 'pickling an object to S3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickled data storage under directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "@delegates(pickSave)\n",
    "def savePklToDir(toDir, fName, ob, **kwargs) :\n",
    "    \"\"\"\n",
    "    Saves a pickled object to a file under a directory, optionally using gzip compression.\n",
    "    Creates the directory if it doesn't exist.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(toDir) :\n",
    "        os.makedirs(toDir)\n",
    "    pickSave(os.path.join(toDir, fName), ob, **kwargs)\n",
    "\n",
    "@delegates(pickLoad)\n",
    "def loadPklFromDir(fromDir, fName, defaultVal, **kwargs) :\n",
    "    \"\"\"\n",
    "    Load a pickled object from a file under a directory, optionally using gzip compression.\n",
    "    Returns a default value if the file doesn't exist.\n",
    "    \"\"\"\n",
    "    fpath = os.path.join(fromDir, fName)\n",
    "    if os.path.exists(fpath) :\n",
    "        return pickLoad(fpath, **kwargs)\n",
    "    else :\n",
    "        return defaultVal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test pickled data storage under directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savePklToDir('testdirpkl','test.pkl', test_rand)\n",
    "assert test_rand == loadPklFromDir('testdirpkl','test.pkl',None)\n",
    "time.sleep(1)\n",
    "os.unlink(os.path.join('testdirpkl','test.pkl'))\n",
    "os.rmdir('testdirpkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickled dict storage split by key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "@delegates(pickSave)\n",
    "def saveSplitPklToDir(m, toDir, fSuff='m.pkl', dirtySet=None, **kwargs) :\n",
    "    \"\"\"\n",
    "    Saves a dict with str keys to a separate file for each key.\n",
    "    If dirtySet is True, saves all keys.\n",
    "    If dirtySet is None (default), saves only keys that don't yet have a file saved.\n",
    "    Otherwise, also saves keys k in dirtySet.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(toDir) :\n",
    "        os.makedirs(toDir)\n",
    "    for k in sorted(m.keys()) :\n",
    "        fPath = os.path.join(toDir, k+fSuff)\n",
    "        if dirtySet is True :\n",
    "            needToSave = True\n",
    "        else :\n",
    "            needToSave = not os.path.exists(fPath)\n",
    "            if dirtySet is not None :\n",
    "                needToSave = needToSave or (k in dirtySet)\n",
    "        if needToSave :\n",
    "            pickSave(fPath, m[k], **kwargs)\n",
    "\n",
    "@delegates(pickLoad)\n",
    "def loadSplitPklFromDir(fromDir, startK=None, endK=None, fSuff='m.pkl', **kwargs) :\n",
    "    \"\"\"\n",
    "    Loads a pickled dict with str keys stored with a separate file for each key,\n",
    "    optionally restricting to keys in [startK .. endK)\n",
    "    \"\"\"\n",
    "    m = {}\n",
    "    if not os.path.exists(fromDir) :\n",
    "        return m\n",
    "    fNames = sorted(fName for fName in os.listdir(fromDir)\n",
    "                    if fName.endswith(fSuff))\n",
    "    for fName in fNames :\n",
    "        fPref = fName[:-len(fSuff)]\n",
    "        if ((startK is not None and fPref<startK)\n",
    "                or (endK is not None and endK<=fPref)) :\n",
    "            continue\n",
    "        m[fPref] = pickLoad(os.path.join(fromDir,fName), **kwargs)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test pickled dict storage split by key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveSplitPklToDir(test_rand, 'testsplitpkl')\n",
    "assert test_rand == loadSplitPklFromDir('testsplitpkl')\n",
    "test_sub = dict((k,v) for k,v in test_rand.items() if 'r3'<=k<'r7')\n",
    "assert test_sub == loadSplitPklFromDir('testsplitpkl',startK='r3',endK='r7')\n",
    "time.sleep(1)\n",
    "for k in test_rand.keys() :\n",
    "    os.unlink(os.path.join('testsplitpkl',k+'m.pkl'))\n",
    "os.rmdir('testsplitpkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YYYYMMDD Date strings\n",
    "A few functions for working date string in the format YYYYMMDD, as used in some SEC URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def addMissingOnesF(dateStr) :\n",
    "    if len(dateStr) == 4 :\n",
    "        return dateStr + '0101'\n",
    "    if len(dateStr) == 6 :\n",
    "        return dateStr + '01'\n",
    "    return dateStr\n",
    "\n",
    "def toDateStr(d=None, addMissingOnes=False) :\n",
    "    \"\"\"\n",
    "    Converts date object or ISO format date string to YYYYMMDD format string;\n",
    "    leaves YYYYMMDD format strings unchanged;\n",
    "    None -> today.\n",
    "    \"\"\"\n",
    "    if isinstance(d,str) :\n",
    "        dateStr = d\n",
    "    else :\n",
    "        if d is None :\n",
    "            d = curEasternUSTime()\n",
    "        elif isinstance(d,int) :\n",
    "            d = curEasternUSTime() + datetime.timedelta(d)\n",
    "        dateStr = d.isoformat()[:10]\n",
    "    dateStr = dateStr.replace('-','').replace('/','')\n",
    "    if addMissingOnes :\n",
    "        dateStr = addMissingOnesF(dateStr)\n",
    "    return dateStr\n",
    "\n",
    "dateStr8Pat = re.compile(r\"(\\d\\d\\d\\d)(\\d\\d)(\\d\\d)$\")\n",
    "def toDate(d=None, addMissingOnes=False) :\n",
    "    \"\"\"\n",
    "    Converts date string in ISO or YYYYMMDD format to date object;\n",
    "    leaves date objects unchanged;\n",
    "    None -> today.\n",
    "    \"\"\"\n",
    "    if isinstance(d,str) :\n",
    "        dateStr = d.replace('-','').replace('/','')\n",
    "        if addMissingOnes :\n",
    "            dateStr = addMissingOnesF(dateStr)\n",
    "        m = dateStr8Pat.match(dateStr)\n",
    "        if m is None :\n",
    "            raise Exception('invalid date str \"'+d+'\"')\n",
    "        return datetime.date(int(m.group(1)),int(m.group(2)),int(m.group(3)))\n",
    "    if d is None :\n",
    "        return curEasternUSTime()\n",
    "    if isinstance(d,int) :\n",
    "        return curEasternUSTime() + datetime.timedelta(d)\n",
    "    return d\n",
    "\n",
    "def isWeekend(d) :\n",
    "    \"Says if date string or date object is on a weekend (Saturday or Sunday).\"\n",
    "    return toDate(d).weekday() >= 5\n",
    "\n",
    "def dateStrsBetween(d1,d2=None,excludeWeekends=False) :\n",
    "    \"\"\"\n",
    "    Returns a list of date strings in YYYYMMDD format from d1 (inclusive)\n",
    "    to d2 (exclusive), optionally excluding weekends.\n",
    "    \"\"\"\n",
    "    d1 = toDate(d1)\n",
    "    d2Str = toDateStr(d2)\n",
    "    res = []\n",
    "    while True :\n",
    "        d1Str = toDateStr(d1)\n",
    "        if d1Str >= d2Str :\n",
    "            break\n",
    "        if not (excludeWeekends and isWeekend(d1)) :\n",
    "            res.append(d1Str)\n",
    "        d1 = d1 + datetime.timedelta(1)\n",
    "    return res\n",
    "\n",
    "def formatDateStr(dStr,sep='-') :\n",
    "    \"Convert YYYYMMDD format date string to YYYY-MM-DD.\"\n",
    "    return sep.join((dStr[:4],dStr[4:6],dStr[6:8]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test YYYYMMDD date string functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert toDateStr('2022',True)=='20220101'\n",
    "assert dateStrsBetween('20201230','20210103')==['20201230', '20201231', '20210101', '20210102']\n",
    "assert dateStrsBetween('20201231','20210106',excludeWeekends=True)==['20201231', '20210101', '20210104', '20210105']\n",
    "assert formatDateStr('20200630')=='2020-06-30'\n",
    "assert formatDateStr('20200630','/')=='2020/06/30'\n",
    "assert (isWeekend('20210605'),isWeekend('20210606'),isWeekend('20210607')) == (True,True,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get current Eastern US time\n",
    "This is used to control when to check for SEC filings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "easternUSTimeZone = timezone('US/Eastern')\n",
    "def curEasternUSTime() :\n",
    "    return datetime.datetime.now(easternUSTimeZone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-19T11:36:44.155584-04:00\n"
     ]
    }
   ],
   "source": [
    "print(curEasternUSTime().isoformat())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanitize text\n",
    "Clean partial text scraped from SEC filings so it can be included in HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def sanitizeText(s) :\n",
    "    if '&' in s[-10:] :\n",
    "        s = s[:s.rindex('&')]\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some functions for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def secBrowse(accessNo) :\n",
    "    \"Open the index page of an SEC filing specified by accession number in a web browser.\"\n",
    "    webbrowser.open_new_tab(secIndexUrl(accessNo,True))\n",
    "\n",
    "def printSamp(m,n=10) :\n",
    "    \"\"\"\n",
    "    Prints a sample of n items from object m , where m is a list or dict;\n",
    "    for other objects just prints the whole thing.\n",
    "    \"\"\"\n",
    "    if isinstance(m,list) :\n",
    "        for i,item in enumerate(m[:n]) :\n",
    "            print(i,end=' ')\n",
    "            printSamp(item,n)\n",
    "    elif isinstance(m,dict) :\n",
    "        for k in m.keys()[:n] :\n",
    "            print(k,end=' ')\n",
    "            printSamp(m[k],n)\n",
    "    else :\n",
    "        print(m)\n",
    "\n",
    "def printErrInfoOrAccessNo(msg,infoOrAccessNo) :\n",
    "    print(msg,end=' ')\n",
    "    if isinstance(infoOrAccessNo,str) and accessNoPat.match(infoOrAccessNo) :\n",
    "        print(secIndexUrl(infoOrAccessNo,True))\n",
    "    else :\n",
    "        print(repr(infOrAccessNo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# uncomment and run to regenerate all library Python files\n",
    "# from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
