{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# utils\n",
    "\n",
    "> Assorted low-level utilities for a flexible SEC filings scanner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from nbdev import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "import gzip\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "from pytz import timezone\n",
    "import requests\n",
    "import time\n",
    "import webbrowser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set directory for scraped data\n",
    "We store all scraped data under stockDataRoot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "stockDataRoot = os.path.expanduser(os.path.join('~','secData2'))\n",
    "def setStockDataRoot(loc) :\n",
    "    \"Set location for storing scraped stock data.\"\n",
    "    global stockDataRoot\n",
    "    stockDataRoot = loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ikedi\\secData2\n"
     ]
    }
   ],
   "source": [
    "print(stockDataRoot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low-level download functions\n",
    "We download SEC data using the requests library.\n",
    "We retry a few times in case of a temporary internet glitch,\n",
    "and also recognize an SEC-specific temporary outage message and raise an Exception for it\n",
    "so that we can flag the problem and retry later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def requestUrl(url, timeout=5.0, nTries=5, returnText=False, **kwargs) :\n",
    "    \"Downloads a URL using the requests package.\"\n",
    "    for i in range(nTries) :\n",
    "        try :\n",
    "            r = requests.get(url,timeout=timeout,params=kwargs)\n",
    "            r.raise_for_status()\n",
    "            return r.text if returnText else r\n",
    "        except Exception as e :\n",
    "            print('Error','downloading',url,'-',e,'; retrying ...')\n",
    "            if i >= nTries-1 :\n",
    "                raise\n",
    "\n",
    "accessNoPatStr = r'\\d{10}-\\d+-\\d+'\n",
    "accessNoPat = re.compile(accessNoPatStr)\n",
    "def secIndexUrl(accessNo, includePref=False) :\n",
    "    \"Returns the url for the index page of an SEC filing specified by accession number.\"\n",
    "    return ((secUrlPref if includePref else '')\n",
    "            + '/Archives/edgar/data/'+accessNo.replace('-','')\n",
    "            +'/'+accessNo+'-index.htm')\n",
    "\n",
    "secUrlPref = 'https://www.sec.gov'\n",
    "pageUnavailablePat = re.compile('page is temporarily unavailable',re.IGNORECASE)\n",
    "def downloadSecUrl(secSubUrlOrAccessNo, soupify=False) :\n",
    "    \"\"\"\n",
    "    Downloads a page from the SEC site. The page can be specified by\n",
    "    a sub-URL (ex. /cgi-bin/browse-edgar?CIK=0000716314&owner=exclude),\n",
    "    or just by an accession number (ex. 0001193125-21-181366), in which\n",
    "    case the index page for that filing is downloaded.\n",
    "    \n",
    "    Optionally parses the page contents into a BeautifulSoup object.\n",
    "\n",
    "    Checks for an SEC-specific temporary outage message, and raises an\n",
    "    Exception if it's detected, so that we can possibly flag to retry\n",
    "    the download later.\n",
    "    \"\"\"\n",
    "    if accessNoPat.match(secSubUrlOrAccessNo) :\n",
    "        secSubUrl = secIndexUrl(secSubUrlOrAccessNo)\n",
    "    else :\n",
    "        secSubUrl = secSubUrlOrAccessNo\n",
    "    urlContents = requestUrl(secUrlPref+secSubUrl).text\n",
    "    if pageUnavailablePat.search(urlContents) :\n",
    "        raise Exception('temporary SEC outage')\n",
    "    if soupify :\n",
    "        return BeautifulSoup(urlContents,'html.parser')\n",
    "    return urlContents\n",
    "\n",
    "spacesPat = re.compile(r'\\s+')\n",
    "def getCombSoupText(tag) :\n",
    "    \"Get the combined text from a BeautifulSoup tag.\"\n",
    "    return spacesPat.sub(\" \",\" \".join(tag.stripped_strings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accessNoPat.match('000119315-21-181366')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test downloading from the SEC website:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = downloadSecUrl('')\n",
    "assert 'securities and exchange' in t.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL: /Archives/edgar/data/000090910821000051/0000909108-21-000051-index.htm\n",
      "Error downloading https://www.sec.gov/Archives/edgar/data/000090910821000051/0000909108-21-000051-index.htm - 403 Client Error: Forbidden for url: https://www.sec.gov/Archives/edgar/data/000090910821000051/0000909108-21-000051-index.htm ; retrying ...\n",
      "Company name HTML: <span class=\"companyName\">DIAMOND HILL INVESTMENT GROUP INC (Filer)\n",
      " <acronym title=\"Central Index Key\">CIK</acronym>: <a href=\"/cgi-bin/browse-edgar?CIK=0000909108&amp;action=getcompany\">0000909108 (see all company filings)</a></span>\n",
      "Company name text: DIAMOND HILL INVESTMENT GROUP INC (Filer) CIK : 0000909108 (see all company filings)\n"
     ]
    }
   ],
   "source": [
    "testUrl = secIndexUrl('0000909108-21-000051')\n",
    "print('URL:',testUrl)\n",
    "s = downloadSecUrl(testUrl, soupify=True)\n",
    "s = s.find('span','companyName')\n",
    "print('Company name HTML:',s)\n",
    "companyName = getCombSoupText(s)\n",
    "print('Company name text:',companyName)\n",
    "assert companyName.lower().startswith('diamond hill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low-level functions for storing scraped data\n",
    "We store scraped data in pickled format,\n",
    "either storing an object in a single pickled file\n",
    "or storing a dict by saving one file per key\n",
    "(for example, one file per date).\n",
    "We can optionally use gzip compression (smaller files, but slower to read)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def openFp(fpath, mode, use_gzip) :\n",
    "    \"Open a file for writing or reading, optionally using gzip compression.\"\n",
    "    openfunc = gzip.open if use_gzip else open\n",
    "    return openfunc(fpath,mode)\n",
    "\n",
    "def pickSave(fpath, ob, use_gzip=False, **kwargs) :\n",
    "    \"Save a pickled object to a file, optionally using gzip compression.\"\n",
    "    with openFp(fpath, 'wb', use_gzip) as f :\n",
    "        pickle.dump(ob, f, **kwargs)\n",
    "\n",
    "def pickLoad(fpath, use_gzip=False) :\n",
    "    \"Load a pickled object from a file, optionally using gzip compression.\"\n",
    "    with openFp(fpath, 'rb', use_gzip) as f :\n",
    "        return pickle.load(f)\n",
    "\n",
    "def pickLoadIfPath(path_or_ob, use_gzip=False) :\n",
    "    \"\"\"\n",
    "    If given a path, loads a pickled object from it; otherwise returns\n",
    "    its argument unchanged (assumes it's an already loaded object).\n",
    "    \"\"\"\n",
    "    if isinstance(path_or_ob,str) :\n",
    "        return pickLoad(path_or_ob, use_gzip=use_gzip)\n",
    "    else :\n",
    "        return path_or_ob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test pickled data storage in single files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "rng = random.Random(42)\n",
    "test_rand = dict((f'r{i}', rng.random()) for i in range(10))\n",
    "pickSave('test.pkl', test_rand)\n",
    "assert test_rand == pickLoad('test.pkl')\n",
    "pickSave('test.pkl', test_rand, use_gzip=True)\n",
    "assert test_rand == pickLoad('test.pkl', use_gzip=True)\n",
    "time.sleep(1)\n",
    "os.unlink('test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def savePklToDir(toDir, fName, ob, use_gzip=False, **kwargs) :\n",
    "    \"\"\"\n",
    "    Saves a pickled object to a file under a directory, optionally using gzip compression.\n",
    "    Creates the directory if it doesn't exist.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(toDir) :\n",
    "        os.makedirs(toDir)\n",
    "    fPath = os.path.join(toDir, fName)\n",
    "    pickSave(fPath, ob, use_gzip=use_gzip, **kwargs)\n",
    "\n",
    "def loadPklFromDir(fromDir, fName, defaultVal, use_gzip=False) :\n",
    "    \"\"\"\n",
    "    Load a pickled object from a file under a directory, optionally using gzip compression.\n",
    "    Returns a default value if the file doesn't exist.\n",
    "    \"\"\"\n",
    "    fPath = os.path.join(fromDir, fName)\n",
    "    if os.path.exists(fPath) :\n",
    "        return pickLoad(fPath, use_gzip=use_gzip)\n",
    "    else :\n",
    "        return defaultVal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test pickled data storage under directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savePklToDir('testdirpkl','test.pkl', test_rand)\n",
    "assert test_rand == loadPklFromDir('testdirpkl','test.pkl',None)\n",
    "time.sleep(1)\n",
    "os.unlink(os.path.join('testdirpkl','test.pkl'))\n",
    "os.rmdir('testdirpkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def saveSplitPklToDir(m, toDir, fSuff='m.pkl', dirtyMap=None, use_gzip=False, **kwargs) :\n",
    "    \"\"\"\n",
    "    Saves a dict with str keys to a separate file for each key.\n",
    "    If dirtyMap is True, saves all keys.\n",
    "    If dirtyMap is None (default), saves only keys that don't yet have a file saved.\n",
    "    Otherwise, also saves keys k for which dirtyMap.get(k) is true.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(toDir) :\n",
    "        os.makedirs(toDir)\n",
    "    for k in sorted(m.keys()) :\n",
    "        fPath = os.path.join(toDir, k+fSuff)\n",
    "        if dirtyMap is True :\n",
    "            needToSave = True\n",
    "        else :\n",
    "            needToSave = not os.path.exists(fPath)\n",
    "            if dirtyMap is not None :\n",
    "                needToSave = needTooSave or dirtyMap.get(k)\n",
    "        if needToSave :\n",
    "            pickSave(fPath, m[k], use_gzip=use_gzip, **kwargs)\n",
    "\n",
    "def loadSplitPklFromDir(fromDir, startK=None, endK=None, fSuff='m.pkl') :\n",
    "    \"\"\"\n",
    "    Loads a pickled dict with str keys stored with a separate file for each key,\n",
    "    optionally restricting to keys in [startK .. endK)\n",
    "    \"\"\"\n",
    "    m = {}\n",
    "    if not os.path.exists(fromDir) :\n",
    "        return m\n",
    "    fNames = sorted(fName for fName in os.listdir(fromDir)\n",
    "                    if fName.endswith(fSuff))\n",
    "    for fName in fNames :\n",
    "        fPref = fName[:-len(fSuff)]\n",
    "        if ((startK is not None and fPref<startK)\n",
    "                or (endK is not None and endK<=fPref)) :\n",
    "            continue\n",
    "        m[fPref] = pickLoad(os.path.join(fromDir,fName))\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test pickled dict storage split by key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveSplitPklToDir(test_rand, 'testsplitpkl')\n",
    "assert test_rand == loadSplitPklFromDir('testsplitpkl')\n",
    "test_sub = dict((k,v) for k,v in test_rand.items() if 'r3'<=k<'r7')\n",
    "assert test_sub == loadSplitPklFromDir('testsplitpkl',startK='r3',endK='r7')\n",
    "time.sleep(1)\n",
    "for k in test_rand.keys() :\n",
    "    os.unlink(os.path.join('testsplitpkl',k+'m.pkl'))\n",
    "os.rmdir('testsplitpkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YYYYMMDD Date strings\n",
    "A few functions for working date string in the format YYYYMMDD, as used in some SEC URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def toDateStr(d=None) :\n",
    "    \"\"\"\n",
    "    Converts date object or ISO format date string to YYYYMMDD format string;\n",
    "    leaves YYYYMMDD format strings unchanged;\n",
    "    None -> today.\n",
    "    \"\"\"\n",
    "    if isinstance(d,str) :\n",
    "        dateStr = d\n",
    "    else :\n",
    "        if d is None :\n",
    "            d = curEasternUSTime()\n",
    "        dateStr = d.isoformat()[:10]\n",
    "    return dateStr.replace('-','').replace('/','')\n",
    "\n",
    "dateStr8Pat = re.compile(r\"(\\d\\d\\d\\d)(\\d\\d)(\\d\\d)$\")\n",
    "def toDate(d=None) :\n",
    "    \"\"\"\n",
    "    Converts date string in ISO or YYYYMMDD format to date object;\n",
    "    leaves date objects unchanged;\n",
    "    None -> today.\n",
    "    \"\"\"\n",
    "    if isinstance(d,str) :\n",
    "        dateStr = d.replace('-','').replace('/','')\n",
    "        m = dateStr8Pat.match(dateStr)\n",
    "        if m is None :\n",
    "            raise Exception('invalid date str \"'+d+'\"')\n",
    "        return datetime.date(int(m.group(1)),int(m.group(2)),int(m.group(3)))\n",
    "    if d is None :\n",
    "        return curEasternUSTime()\n",
    "    return d\n",
    "\n",
    "def isWeekend(d) :\n",
    "    \"Says if date string or date object is on a weekend (Saturday or Sunday).\"\n",
    "    return toDate(d).weekday() >= 5\n",
    "\n",
    "def dateStrsBetween(d1,d2=None,excludeWeekends=False) :\n",
    "    \"\"\"\n",
    "    Returns a list of date strings in YYYYMMDD format from d1 (inclusive)\n",
    "    to d2 (exclusive), optionally excluding weekends.\n",
    "    \"\"\"\n",
    "    d1 = toDate(d1)\n",
    "    d2Str = toDateStr(d2)\n",
    "    res = []\n",
    "    while True :\n",
    "        d1Str = toDateStr(d1)\n",
    "        if d1Str >= d2Str :\n",
    "            break\n",
    "        if not (excludeWeekends and isWeekend(d1)) :\n",
    "            res.append(d1Str)\n",
    "        d1 = d1 + datetime.timedelta(1)\n",
    "    return res\n",
    "\n",
    "def formatDateStr(dStr,sep='-') :\n",
    "    \"Convert YYYYMMDD format date string to YYYY-MM-DD.\"\n",
    "    return sep.join((dStr[:4],dStr[4:6],dStr[6:8]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test YYYYMMDD date string functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert dateStrsBetween('20201230','20210103')==['20201230', '20201231', '20210101', '20210102']\n",
    "assert dateStrsBetween('20201231','20210106',excludeWeekends=True)==['20201231', '20210101', '20210104', '20210105']\n",
    "assert formatDateStr('20200630')=='2020-06-30'\n",
    "assert formatDateStr('20200630','/')=='2020/06/30'\n",
    "assert (isWeekend('20210605'),isWeekend('20210606'),isWeekend('20210607')) == (True,True,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get current Eastern US time\n",
    "This is used to control when to check for SEC filings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "easternUSTimeZone = timezone('US/Eastern')\n",
    "def curEasternUSTime() :\n",
    "    return datetime.datetime.now(easternUSTimeZone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-05T12:41:11.647654-04:00\n"
     ]
    }
   ],
   "source": [
    "print(curEasternUSTime().isoformat())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some functions for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def secBrowse(accessNo) :\n",
    "    \"Open the index page of an SEC filing specified by accession number in a web browser.\"\n",
    "    webbrowser.open_new_tab(secIndexUrl(accessNo,True))\n",
    "\n",
    "def printSamp(m,n=10) :\n",
    "    \"\"\"\n",
    "    Prints a sample of n items from object m , where m is a list or dict;\n",
    "    for other objects just prints the whole thing.\n",
    "    \"\"\"\n",
    "    if isinstance(m,list) :\n",
    "        for i,item in enumerate(m[:n]) :\n",
    "            print(i,end=' ')\n",
    "            printSamp(item,n)\n",
    "    elif isinstance(m,dict) :\n",
    "        for k in m.keys()[:n] :\n",
    "            print(k,end=' ')\n",
    "            printSamp(m[k],n)\n",
    "    else :\n",
    "        print(m)\n",
    "\n",
    "def printErrInfoOrAccessNo(msg,infoOrAccessNo) :\n",
    "    print(msg,end=' ')\n",
    "    if isinstance(infoOrAccessNo,str) and accessNoPat.match(infoOrAccessNo) :\n",
    "        print(secIndexUrl(infoOrAccessNo,True))\n",
    "    else :\n",
    "        print(repr(infOrAccessNo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# uncomment and run to regenerate all library Python files\n",
    "# from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
