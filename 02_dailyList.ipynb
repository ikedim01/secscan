{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp dailyList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dailyList\n",
    "\n",
    "> Parse the SEC's archived daily list of filings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from nbdev import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import collections\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "\n",
    "from secscan import utils,recentFeed\n",
    "\n",
    "defaultDLDir = os.path.join(utils.stockDataRoot,'dlMaps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and parse the SEC's archived daily list of filings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def getQStr(dateStr) :\n",
    "    \"\"\"\n",
    "    Converts a date in YYYYMMDD format to YYYY/QTRn/\n",
    "    where n is the quarter number from 1 to 4.\"\n",
    "    \"\"\"\n",
    "    return dateStr[:4] + '/QTR' + str((int(dateStr[4:6])+2) // 3) + '/'\n",
    "\n",
    "def getSecDailyIndexUrls(dateStr) :\n",
    "    base = '/Archives/edgar/daily-index/'+getQStr(dateStr)\n",
    "    return (base+'master.'+dateStr+'.idx', base+'index.json')\n",
    "\n",
    "edgarTxtFPat = re.compile(\n",
    "            # gets cik and accession no from a file url within the daily index\n",
    "            r\"\\s*edgar/data/(\\d+)\" # cik - should be same as on the index line\n",
    "            + r\"/(\"+utils.accessNoPatStr+r\")\\.txt\\s*$\", # accession no\n",
    "            re.IGNORECASE)\n",
    "\n",
    "def getDailyFList(d, listIndexCache=None) :\n",
    "    \"\"\"\n",
    "    Returns a list of SEC filed forms:\n",
    "        [(cik, cikName, formType, fileDate, accNo), ... ]\n",
    "    for the given date or ISO date string, retrieved from\n",
    "    the SEC daily index.\n",
    "    \"\"\"\n",
    "    dateStr = utils.toDateStr(d)\n",
    "    listUrl, listIndexUrl = getSecDailyIndexUrls(dateStr)\n",
    "    if listIndexCache is None or listIndexUrl not in listIndexCache :\n",
    "        listIndexJson = utils.downloadSecUrl(listIndexUrl, toFormat='json')\n",
    "        listIndex = set(item['name'] for item in listIndexJson['directory']['item']\n",
    "                        if item['name'].startswith('master'))\n",
    "        print(f'### list index {len(listIndex)}',end=' ')\n",
    "        if listIndexCache is not None :\n",
    "            listIndexCache[listIndexUrl] = listIndex\n",
    "    else :\n",
    "        listIndex = listIndexCache[listIndexUrl]\n",
    "    if 'master.'+dateStr+'.idx' not in listIndex :\n",
    "        print('HOLIDAY',end=' ')\n",
    "        return []\n",
    "    res = downloadSecFormList(listUrl)\n",
    "    print('count for',dateStr+':', len(res), end=' ')\n",
    "    return res\n",
    "\n",
    "def downloadSecFormList(listUrl) :\n",
    "    fListRes = utils.downloadSecUrl(listUrl)\n",
    "    r = csv.reader(fListRes.splitlines(), delimiter='|')\n",
    "    res = []\n",
    "    for entry in r :\n",
    "        if len(entry)==5 and entry[0].isdigit() :\n",
    "            cik, cikName, formType, fileDate, txtF = entry\n",
    "        else :\n",
    "            if len(res) > 0 :\n",
    "                print('invalid entry', entry)\n",
    "            continue\n",
    "        fileDate = fileDate.replace('-','').replace('/','')\n",
    "        m = edgarTxtFPat.match(txtF)\n",
    "        if not m :\n",
    "            print('missing accession no in', entry)\n",
    "            continue\n",
    "        if m.group(1) != cik :\n",
    "            print('cik mismatch in', entry)\n",
    "        res.append((cik,cikName,formType,fileDate,m.group(2)))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test downloading and parsing SEC's archived daily list of filings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### list index 64 HOLIDAY ### list index 61 count for 20201201: 3464 "
     ]
    }
   ],
   "source": [
    "assert ((getQStr('20200101'),getQStr('20200401'),getQStr('20201201'))\n",
    "        == ('2020/QTR1/','2020/QTR2/','2020/QTR4/')), \"quarter string calc\"\n",
    "assert (getSecDailyIndexUrls('20201201')\n",
    "        ==('/Archives/edgar/daily-index/2020/QTR4/master.20201201.idx',\n",
    "           '/Archives/edgar/daily-index/2020/QTR4/index.json')), \"daily index URL\"\n",
    "assert getDailyFList('20210531')==[],\"daily list holiday test\"\n",
    "r = getDailyFList('20201201')\n",
    "assert len(r)==3464 and r[-1]== ('97745', 'THERMO FISHER SCIENTIFIC INC.',\n",
    "                                 '8-K', '20201201', '0000097745-20-000055'), \"daily list regular day test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Form classes (how to specify groups of form types):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "namedFormClasses = {  # readable names for some groups of form types\n",
    "    'ALL' : '',\n",
    "    'FINANCIAL' : re.compile('10-[KQ]',re.IGNORECASE),\n",
    "    'ACTIVIST' : 'SC 13D',\n",
    "    'FIVEPERCENT' : re.compile('SC 13[DG]',re.IGNORECASE),\n",
    "    'INVESTOR' : '13F-HR',\n",
    "    'ALLINVESTOR' : re.compile('13F-HR|SC 13[DG]',re.IGNORECASE),\n",
    "    'INSIDER' : re.compile('4(?:/A)?$',re.IGNORECASE),\n",
    "}\n",
    "\n",
    "noPeriodFormTypes = re.compile('SC 13[DG]|424',re.IGNORECASE)\n",
    "\n",
    "def isInFormClass(formClass,formType) :\n",
    "    \"\"\"\n",
    "    Says if formType is in formClass, where formClass can be one of the following:\n",
    "        - None or '' - includes all formTypes\n",
    "        - namedFormClass - one of the ones above\n",
    "        - other string - includes formTypes starting with that string\n",
    "        - regex - includes matching formTypes\n",
    "    \"\"\"\n",
    "    if formClass is None :\n",
    "        return True\n",
    "    if isinstance(formClass,str) :\n",
    "        formClass = formClass.upper()\n",
    "        if formClass in namedFormClasses :\n",
    "            formClass = namedFormClasses[formClass]\n",
    "    if isinstance(formClass,str) :\n",
    "        return formType.startswith(formClass)\n",
    "    # else assume it's a regex\n",
    "    return formClass.match(formType) is not None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test form classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ((isInFormClass(None,'10-Q'),isInFormClass('10','10-Q'),isInFormClass('4','10-Q'))\n",
    "        == (True,True,False)), \"string form classes\"\n",
    "assert ((isInFormClass('INVESTOR','13F-HR'),isInFormClass('investor','10-Q'))\n",
    "        == (True,False)), \"names form classes\"\n",
    "assert ((isInFormClass(noPeriodFormTypes,'SC 13D'),isInFormClass(noPeriodFormTypes,'10-Q'))\n",
    "        == (True,False)), \"regex form class\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dailyList class maintains a trio of dicts:\n",
    "```\n",
    "    dl: dateStr -> list of filings [(cik, formType, accNo, fDate), ... ]\n",
    "    cikNames: cik -> (name, latestDateStr)\n",
    "    cikOldNames: cik -> [name1, name2, ...]\n",
    "```\n",
    "using the SEC's archived daily list of filings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "\n",
    "def findCikName(cikName,oldNames) :\n",
    "    \"\"\"\n",
    "    Checks if a CIK name already appears in a list of old names (case insensitive).\n",
    "    Returns the position if it appears, else -1.\n",
    "    \"\"\"\n",
    "    cikName = cikName.casefold()\n",
    "    for i,oldName in enumerate(oldNames) :\n",
    "        if cikName == oldName.casefold() :\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "def checkMapDates(dMap, verbose=True) :\n",
    "    \"Prints info on dates present present in a map, checking for missing dates.\"\n",
    "    startD = min(dMap.keys())\n",
    "    endD = max(dMap.keys())\n",
    "    print(f'start date: {startD}, end date: {endD}')\n",
    "    nNotPresent = 0\n",
    "    for dStr in utils.dateStrsBetween(startD,endD) :\n",
    "        if dStr not in dMap :\n",
    "            nNotPresent += 1\n",
    "            if verbose :\n",
    "                print(dStr,'not present!')\n",
    "    print(f'total of {len(dMap)} dates, {nNotPresent} missing')\n",
    "\n",
    "class dailyList(object) :\n",
    "    def __init__(self, dlDir=defaultDLDir, startD=None, endD=None, fSuff='m.pkl', **pickle_kwargs) :\n",
    "        \"\"\"\n",
    "        Creates a dailyList object and loads lists for the date range [startD..endD), along with\n",
    "        the full CIK name maps. By default (startD=None, endD=None) loads all dates present.\n",
    "        Use startD='empty' to create an empty object.\n",
    "        \"\"\"\n",
    "        self.dlDir = dlDir\n",
    "        self.fSuff = fSuff\n",
    "        self.pickle_kwargs = dict(pickle_kwargs)\n",
    "        self.dl = {}\n",
    "        if startD=='empty' :\n",
    "            self.cikNames, self.cikOldNames = {}, {}\n",
    "            return\n",
    "        self.loadDays(startD=startD, endD=endD)\n",
    "        self.cikNames = utils.loadPklFromDir(dlDir, 'cikNames.pkl', {}, **pickle_kwargs)\n",
    "        self.cikOldNames = utils.loadPklFromDir(dlDir, 'cikOldNames.pkl', {}, **pickle_kwargs)\n",
    "    def loadDays(self, startD=None, endD=None) :\n",
    "        \"\"\"\n",
    "        Loads lists for the given date range into an already created dailyList object.\n",
    "        \"\"\"\n",
    "        self.dl.update(utils.loadSplitPklFromDir(self.dlDir, startK=startD, endK=endD,\n",
    "                                                 fSuff=self.fSuff, **self.pickle_kwargs))\n",
    "    def save(self, dirtySet=None) :\n",
    "        \"\"\"\n",
    "        Saves daily lists and name maps to self.dlDir.\n",
    "        By default just saves days with no list already present.\n",
    "        See utils.saveSplitPklToDir for other possibilities based on the dirtySet argument.\n",
    "        \"\"\"\n",
    "        utils.saveSplitPklToDir(self.dl, self.dlDir, dirtySet=dirtySet, fSuff=self.fSuff, **self.pickle_kwargs)\n",
    "        utils.savePklToDir(self.dlDir, 'cikNames.pkl', self.cikNames, **self.pickle_kwargs)\n",
    "        utils.savePklToDir(self.dlDir, 'cikOldNames.pkl', self.cikOldNames, **self.pickle_kwargs)\n",
    "    def updateCikNamesFromEntry(self, dStr, cik, cikName) :\n",
    "        \"\"\"\n",
    "        Updates the name maps\n",
    "            self.cikNames: cik -> (name, latestDateStr)\n",
    "            self.cikOldNames: cik -> [oldname1, oldname2, ... ]\n",
    "        to reflect an entry (cik, cikName, ... ) from the daily index for dStr.\n",
    "        \"\"\"\n",
    "        if cik not in self.cikNames : # completely new name\n",
    "            self.cikNames[cik] = (cikName, dStr)\n",
    "            return\n",
    "        # make sure self.cikNames contains the latest name\n",
    "        if dStr < self.cikNames[cik][1] :\n",
    "            # name in self.cikNames is newer than this entry\n",
    "            oldName = cikName\n",
    "        else :\n",
    "            # this entry is newer than the name in self.cikNames - update it\n",
    "            oldName = self.cikNames[cik][0]\n",
    "            self.cikNames[cik] = (cikName, dStr)\n",
    "        curName = self.cikNames[cik][0]\n",
    "        if curName.casefold() == oldName.casefold() :\n",
    "            # new and old names are the same (case insensitive)\n",
    "            return\n",
    "        # oldName is different from curName - update self.cikOldNames:\n",
    "        if cik not in self.cikOldNames :\n",
    "            self.cikOldNames[cik] = [oldName]\n",
    "            return\n",
    "        # add the old name if it's not in the list of old names:\n",
    "        oldNames = self.cikOldNames[cik]\n",
    "        if findCikName(oldName, oldNames) < 0 :\n",
    "            oldNames.append(oldName)\n",
    "        # delete the current name if it's in the list of old names:\n",
    "        i = findCikName(curName, oldNames)\n",
    "        if i >= 0 :\n",
    "            del oldNames[i]\n",
    "    def updateDayUsingL(self, dStr, dailyL, clearDay=True) :\n",
    "        if clearDay :\n",
    "            self.dl[dStr] = []\n",
    "        for cik, cikName, formType, fileDate, accNo in dailyL :\n",
    "            self.dl[dStr].append((cik, formType, accNo, fileDate))\n",
    "            self.updateCikNamesFromEntry(dStr, cik, cikName)\n",
    "    def checkAgainstMaster(self, year=None, quarter=None, fixMissingDate=False,\n",
    "                           returnMissing=False) :\n",
    "        \"\"\"\n",
    "        Checks this list against the SEC combined master list.\n",
    "        Returns True if no missing filings (filings in master but not in this list).\n",
    "        If missing filings are found:\n",
    "        - if fixMissingDate is False, returns False.\n",
    "        - otherwise tries to fix this list by adding the missing filings and adding it,\n",
    "          and returns True if successful.\n",
    "        \"\"\"\n",
    "        if year is None :\n",
    "            url = '/Archives/edgar/full-index/master.idx'\n",
    "        else :\n",
    "            url = f'/Archives/edgar/full-index/{year}/QTR{quarter}/master.idx'\n",
    "        masterL = downloadSecFormList(url)\n",
    "        allAccNos = self.getAllAccNos()\n",
    "        print('checking against master ...')\n",
    "        missingL = [tup for tup in masterL if tup[-1] not in allAccNos]\n",
    "        if returnMissing :\n",
    "            return missingL\n",
    "        if len(missingL) == 0 :\n",
    "            print('no missing filings found!')\n",
    "            return True\n",
    "        missingFDates = sorted(set(tup[-2] for tup in missingL))\n",
    "        print(len(missingL),'missing filings found, fDates',missingFDates)\n",
    "        print('fTypes',sorted(set(tup[2] for tup in missingL)))\n",
    "        print('accNos[:50]',sorted(set(tup[-1] for tup in missingL))[:50])\n",
    "        if not fixMissingDate :\n",
    "            print('*** RUN WITH fixMissingDate=True TO FIX ***')\n",
    "            return False\n",
    "        if len(missingFDates) != 1 :\n",
    "            print('unable to fix missing dates - ambiguous')\n",
    "            return False\n",
    "        dStr = missingFDates[0]\n",
    "        if dStr not in self.dl :\n",
    "            print('unable to fix missing dates - unexpected day, not in daily map')\n",
    "            return False\n",
    "        print('adding',len(missingL),'entries to',dStr)\n",
    "        self.updateDayUsingL(dStr, missingL, clearDay=False)\n",
    "        self.save(dirtySet={dStr})\n",
    "        return True\n",
    "    def updateForDays(self, startD=None, endD=None) :\n",
    "        \"\"\"\n",
    "        Update to reflect the filings for dates between startD (inclusive)\n",
    "        and endD (exclusive). If startD is None, uses the last date already\n",
    "        in self.dl, or the start of the current year if self.dl is empty.\n",
    "        If endD is None, uses today.\n",
    "        Retrieves the filings info from the SEC daily index using getDailyFList.\n",
    "        \"\"\"\n",
    "        if startD is None :\n",
    "            if len(self.dl) == 0 :\n",
    "                startD = utils.toDateStr()[:4]+'0101' # start of current year\n",
    "            else :\n",
    "                startD = max(self.dl.keys())\n",
    "        listIndexCache = {}\n",
    "        for dStr in reversed(utils.dateStrsBetween(startD,endD)) :\n",
    "            if dStr in self.dl :\n",
    "                print('SKIP'+dStr, end=' ')\n",
    "            elif utils.isWeekend(dStr) :\n",
    "                self.dl[dStr] = []\n",
    "                print('WEEKEND'+dStr, end=' ')\n",
    "            else :\n",
    "                print('UPDATE'+dStr, end=' ')\n",
    "                self.updateDayUsingL(dStr, getDailyFList(dStr,listIndexCache))\n",
    "                print('*',end=' ')\n",
    "    def getAllFormTypes(self) :\n",
    "        \"Returns all form types found.\"\n",
    "        res = set()\n",
    "        for l in self.dl.values() :\n",
    "            res.update(formType for _,formType,_,_ in  l)\n",
    "        return res\n",
    "    def getCiksFiling(self, formClass=None) :\n",
    "        \"Returns all ciks who have filed any forms in formClass.\"\n",
    "        res = set()\n",
    "        for l in self.dl.values() :\n",
    "            res.update(cik for cik,formType,_,_ in l\n",
    "                       if isInFormClass(formClass,formType))\n",
    "        return res\n",
    "    def getAllAccNos(self) :\n",
    "        res = set()\n",
    "        for l in self.dl.values() :\n",
    "            res.update(accNo for _,_,accNo,_ in l)\n",
    "        return res\n",
    "    def getFilingsList(self, ciks=None, formClass=None) :\n",
    "        \"\"\"\n",
    "        Returns a list of filings for the given ciks (may be a set or None for all CIKs),\n",
    "        that are in formClass. The list is is the form:\n",
    "            [(dlDate, name, formType, accNo, fileDate),\n",
    "             ... ]\n",
    "        and is sorted lexicographically on those fields, except in reverse order on dlDate\n",
    "        (most recent dates appear first).\n",
    "        Also returns a dict mapping each cik -> the set of accession numbers for its filings.\n",
    "        \"\"\"\n",
    "        res = []\n",
    "        accNosByCik = collections.defaultdict(set)\n",
    "        for dDate,l in self.dl.items() :\n",
    "            for cik, formType, accNo, fileDate in l :\n",
    "                if (ciks is None or cik in ciks) and isInFormClass(formClass,formType):\n",
    "                    res.append((dDate,self.cikNames[cik][0],formType,accNo,fileDate))\n",
    "                    accNosByCik[cik].add(accNo)\n",
    "        res.sort()\n",
    "        res.sort(key = lambda x : x[0], reverse=True)\n",
    "        return res, accNosByCik\n",
    "    def restrictedCikNameMap(self, ciks) :\n",
    "        \"Create a dict : cik -> latest name restricted to a given list or set of ciks.\"\n",
    "        return dict((cik,self.cikNames[cik][0]) for cik in ciks)\n",
    "    def checkDates(self, verbose=True) :\n",
    "        \"Prints info on dates present, checking for missing dates.\"\n",
    "        checkMapDates(self.dl, verbose=verbose)\n",
    "\n",
    "def dlCountFilings(dlDir=defaultDLDir, startD=None, endD=None, ciks=None,\n",
    "                   formClass=None, noAmend=False,\n",
    "                   fSuff='m.pkl', **pickle_kwargs) :\n",
    "    \"\"\"\n",
    "    Convenience function to count number of filings in a date range, optionally restricting\n",
    "    to ciks and formClass.\n",
    "    \"\"\"\n",
    "    dl = dailyList(dlDir=dlDir, startD=startD, endD=endD, fSuff=fSuff, **pickle_kwargs)\n",
    "    if noAmend :\n",
    "        formClass = re.compile(formClass+'(?!/)',re.IGNORECASE)\n",
    "    fList,_ = dl.getFilingsList(ciks=ciks, formClass=formClass)\n",
    "    return len(fList)\n",
    "\n",
    "def loadAndUpdateDL(dlDir=defaultDLDir, startD=None, endD=None, uStartD=None, uEndD=None,\n",
    "                    fSuff='m.pkl', dirtySet=None, **pickle_kwargs) :\n",
    "    \"\"\"\n",
    "    Creates a dailyList object and loads lists for the date range [startD..endD), along with\n",
    "    the full CIK name maps. By default (startD=None, endD=None) loads all dates present.\n",
    "    Then updates to reflect the filings for dates between uStartD (inclusive)\n",
    "    and uEndD (exclusive), and saves. If uStartD is None, uses the last date already\n",
    "    in the loaded dailyList, or the start of the current year if the loaded dailyList\n",
    "    is empty. If uEndD is None, uses today.\n",
    "    Use startD='empty' to start with an empty dailyList.\n",
    "\n",
    "    A dailyList can be initialized for a date range starting from an empty directory by:\n",
    "        dl = loadAndUpdateDL(dlDir=emptyDir, startD='empty', uStartD=drangeStart, uEndD=drangeEnd)\n",
    "    An dailyList in an existing directory can be updated up to and including yesterday by:\n",
    "        dl = loadAndUpdateDL(dlDir=existingDir)\n",
    "    \"\"\"\n",
    "    dl = dailyList(dlDir=dlDir, startD=startD, endD=endD, fSuff=fSuff, **pickle_kwargs)\n",
    "    dl.updateForDays(startD=uStartD, endD=uEndD)\n",
    "    dl.save(dirtySet=dirtySet)\n",
    "    return dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3081 missing filings found, fDates ['20211001', '20211004', '20211005', '20211006', '20211007', '20211008', '20211011', '20211012', '20211013', '20211014', '20211015', '20211018', '20211019', '20211020', '20211021', '20211022', '20211024', '20211025', '20211026', '20211027', '20211028', '20211029', '20211101', '20211102', '20211103', '20211104', '20211105', '20211108', '20211109', '20211110', '20211111', '20211112', '20211115', '20211116', '20211117', '20211118', '20211119', '20211122', '20211123', '20211124', '20211126', '20211129', '20211130', '20211201', '20211202', '20211203', '20211206', '20211207', '20211208', '20211209', '20211210', '20211213', '20211214', '20211215', '20211216', '20211217', '20211220', '20211221', '20211222', '20211223', '20211227', '20211228', '20211229', '20211230', '20211231']\n",
      "fTypes ['19B-4E', '8-M', 'ABS-EE', 'CFPORTAL', 'CFPORTAL-W', 'CFPORTAL/A', 'CORRESP', 'D/A', 'DOS', 'DOS/A', 'DRS', 'DRS/A', 'DRSLTR', 'EFFECT', 'FOCUSN', 'FOCUSN/A', 'MA-A', 'MA-W', 'MA/A', 'QUALIF', 'SBSE-A/A', 'SEC STAFF ACTION', 'SEC STAFF LETTER', 'TA-1', 'TA-1/A', 'TA-W', 'UPLOAD', 'X-17A-5', 'X-17A-5/A']\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "# # checking for missing filings in old quarter master list (Q4 2021)\n",
    "# # these seem to be specific types (DRS, EFFECT, etc)\n",
    "# dl = dailyList(startD='20211001',endD='20220101')\n",
    "# dl.checkAgainstMaster(2021,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 missing filings found, fDates ['20220804']\n",
      "fTypes ['10-Q', '13F-HR', '3', '4', '8-K', 'D', 'DEFA14A', 'POS EX']\n",
      "accNos[:50] ['0000709283-22-000033', '0000733269-22-000032', '0000899243-22-027699', '0000950170-22-014749', '0001062993-22-017282', '0001069258-22-000053', '0001104659-22-086131', '0001171843-22-005361', '0001171843-22-005362', '0001174947-22-000922', '0001193125-22-212520', '0001209191-22-044415', '0001213900-22-044758', '0001287032-22-000254', '0001289636-22-000026', '0001370880-22-000033', '0001393311-22-000028', '0001443646-22-000155', '0001500435-22-000045', '0001558370-22-012193', '0001604028-22-000051', '0001606366-22-000048', '0001606587-22-001606', '0001628280-22-021070', '0001654954-22-010601', '0001683168-22-005337', '0001683168-22-005338', '0001706946-22-000124', '0001759655-22-000111', '0001939971-22-000001', '0001941353-22-000001']\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "# # fixing missing filings from a specific day (20220804) in the SEC daily index\n",
    "# # using the current quarter master index:\n",
    "# dl = dailyList(startD='20220701') # start of current quarter\n",
    "# dl.checkAgainstMaster()  # check missing fDates and filings, then run next line:\n",
    "# # dl.fixDayFromMaster(dStr='20220804')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test dailyList class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20210611 ### list index 64 filings for 20210611: 4263 * 20210614 ### list index 64 filings for 20210614: 4379 * 20210613 WEEKEND 20210612 WEEKEND SKIP20210611 "
     ]
    }
   ],
   "source": [
    "tdl = dailyList(startD='empty')\n",
    "tdl.updateForDays('20210611','20210612')\n",
    "assert (len(tdl.dl)==1\n",
    "        and len(tdl.dl['20210611'])==4263\n",
    "        and len(tdl.cikNames)==2821\n",
    "        and tdl.dl['20210611'][0]==('1000045', '8-K', '0001564590-21-032560', '20210611')\n",
    "       ), \"initializing daily list\"\n",
    "\n",
    "tdl.updateForDays('20210611','20210615')\n",
    "assert (len(tdl.dl)==4\n",
    "        and [len(tdl.dl[dStr]) for dStr in ['20210611','20210612','20210613','20210614']]==[4263,0,0,4379]\n",
    "        and len(tdl.cikNames)==5063\n",
    "        and tdl.dl['20210614'][0]==('1000230', '10-Q', '0001437749-21-014672', '20210614')\n",
    "       ), \"continuing daily list maps\"\n",
    "\n",
    "assert (len(tdl.getAllFormTypes())==157\n",
    "        and len(tdl.getCiksFiling())==5063\n",
    "        and len(tdl.getCiksFiling('financial'))==110\n",
    "        and min(tdl.getCiksFiling('financial'))=='1000230'), \"checking daily list filings/CIKs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# uncomment and run to regenerate all library Python files\n",
    "# from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
